"""
Framework Question Generator

G√©n√®re des questions d'audit depuis des frameworks (ISO 27001, NIST, etc.) en utilisant
l'IA (DeepSeek) avec batching intelligent et fallback algorithmique.

Workflow:
1. Charger framework + exigences
2. D√©couper en batches (10 exigences/lot)
3. G√©n√©rer via IA par lot
4. Parser et normaliser
5. V√©rifier couverture minimale
6. Relancer pour exigences manquantes

Version: 1.0
Date: 2025-01-08
"""

import logging
from typing import List, Dict, Any, Optional
from uuid import uuid4
from sqlalchemy.orm import Session
from sqlalchemy import text

logger = logging.getLogger(__name__)


class FrameworkQuestionGenerator:
    """
    G√©n√©rateur de questions depuis frameworks de conformit√©.

    D√©pendances inject√©es:
    - http_client: DeepSeekHttpClient pour appels IA
    - parser: DeepSeekResponseParser pour parsing JSON
    - prompt_builder: PromptBuilder pour construction prompts
    """

    def __init__(
        self,
        db_session: Session,
        http_client,
        parser,
        prompt_builder,
        batch_size: int = 10
    ):
        """
        Initialise le g√©n√©rateur.

        Args:
            db_session: Session SQLAlchemy
            http_client: Client HTTP pour IA
            parser: Parser de r√©ponses JSON
            prompt_builder: Constructeur de prompts
            batch_size: Taille des lots (d√©faut: 10)
        """
        self.db = db_session
        self.http_client = http_client
        self.parser = parser
        self.prompt_builder = prompt_builder
        self.batch_size = batch_size

    async def generate(
        self,
        framework_id: str,
        language: str = "fr",
        progress_callback = None  # Callback pour progression SSE
    ) -> List[Dict[str, Any]]:
        """
        G√©n√®re des questions pour un framework donn√©.

        Args:
            framework_id: ID du framework
            language: Langue des questions (d√©faut: "fr")
            progress_callback: Fonction async(batch_idx, total_batches, status, data) pour SSE

        Returns:
            Liste de questions brutes (format dict)

        Raises:
            ValueError: Si framework inexistant
        """
        # 1. Charger framework + exigences
        framework, requirements = self._load_framework_and_requirements(framework_id)

        if not requirements:
            logger.warning(f"‚ö†Ô∏è Aucune exigence trouv√©e pour framework {framework_id}")
            return []

        logger.info(
            f"üìã Framework: {framework.name} - "
            f"{len(requirements)} exigences"
        )

        # 2. Charger criticit√©s depuis control points
        requirement_ids = [str(r.id) for r in requirements]
        cp_map = self._fetch_control_points_for_requirements(requirement_ids)

        # 3. Pr√©parer les items avec m√©tadonn√©es
        items = []
        for r in requirements:
            # R√©cup√©rer la criticit√© du premier CP li√©
            cps = cp_map.get(str(r.id), [])
            criticality = cps[0].get("criticality_level", "MEDIUM") if cps else "MEDIUM"

            items.append({
                "anchor_id": str(r.id),
                "requirement_code": r.official_code,
                "official_code": r.official_code,
                "title": r.title,
                "requirement_text": (r.requirement_text or "")[:600],
                "domain": getattr(r, "domain", None),
                "subdomain": getattr(r, "subdomain", None),
                "criticality_level": criticality,
            })

        # 4. G√©n√©rer par batches
        all_questions = await self._generate_batches(items, language, progress_callback)

        # 5. V√©rifier la couverture des exigences
        covered_req_ids = set()
        for q in all_questions:
            if isinstance(q, dict):
                req_ids = q.get("requirement_ids", [])
                if isinstance(req_ids, list):
                    covered_req_ids.update([str(rid) for rid in req_ids])

        all_req_ids = {str(r.id) for r in requirements}
        uncovered_req_ids = all_req_ids - covered_req_ids

        # 6. Deuxi√®me passe IA si des exigences ne sont pas couvertes
        if uncovered_req_ids:
            logger.warning(
                f"‚ö†Ô∏è {len(uncovered_req_ids)} exigences non couvertes apr√®s premi√®re passe"
            )

            # Callback pour informer du d√©marrage de la deuxi√®me passe
            if progress_callback:
                await progress_callback(0, 1, "second_pass_started", {
                    "missing_count": len(uncovered_req_ids),
                    "message": f"Deuxi√®me passe IA pour {len(uncovered_req_ids)} exigences non couvertes..."
                })

            # R√©cup√©rer les items des exigences manquantes
            uncovered_items = [item for item in items if item.get("anchor_id") in uncovered_req_ids]

            if uncovered_items:
                try:
                    # G√©n√©rer pour les exigences manquantes
                    logger.info(f"üîÑ Deuxi√®me passe pour {len(uncovered_items)} exigences manquantes")
                    second_pass_questions = await self._generate_second_pass(uncovered_items, language)

                    if second_pass_questions:
                        all_questions.extend(second_pass_questions)
                        logger.info(f"‚úÖ Deuxi√®me passe: {len(second_pass_questions)} questions suppl√©mentaires")

                        # Callback pour informer de la fin de la deuxi√®me passe
                        if progress_callback:
                            await progress_callback(0, 1, "second_pass_complete", {
                                "new_questions": len(second_pass_questions),
                                "total_questions": len(all_questions),
                                "message": f"Deuxi√®me passe termin√©e: {len(second_pass_questions)} questions suppl√©mentaires"
                            })

                except Exception as e:
                    logger.error(f"‚ùå Erreur deuxi√®me passe IA: {e}")
                    # Callback pour informer de l'erreur
                    if progress_callback:
                        await progress_callback(0, 1, "second_pass_error", {
                            "error": str(e),
                            "message": f"Erreur deuxi√®me passe: {len(uncovered_req_ids)} exigences non couvertes"
                        })

        logger.info(f"‚úÖ {len(all_questions)} questions g√©n√©r√©es au total")
        return all_questions

    async def _generate_second_pass(
        self,
        uncovered_items: List[Dict[str, Any]],
        language: str = "fr"
    ) -> List[Dict[str, Any]]:
        """
        Deuxi√®me passe IA pour les exigences non couvertes.
        Utilise un prompt sp√©cifique pour garantir la couverture.

        Args:
            uncovered_items: Items des exigences non couvertes
            language: Langue

        Returns:
            Liste de questions suppl√©mentaires
        """
        if not uncovered_items:
            return []

        logger.info(f"üîÑ Deuxi√®me passe: g√©n√©ration pour {len(uncovered_items)} exigences manquantes")

        all_second_pass_questions = []

        # Traiter par petits lots pour ne pas surcharger l'IA
        batches = list(self._chunks(uncovered_items, min(self.batch_size, 5)))

        for idx, batch in enumerate(batches, 1):
            try:
                # Construire un prompt sp√©cifique pour les exigences manquantes
                reqs_text = ""
                for i, item in enumerate(batch, 1):
                    code = item.get("official_code", f"REQ-{i}")
                    title = item.get("title", "")
                    text = item.get("requirement_text", "")
                    req_id = item.get("anchor_id", "")
                    reqs_text += f"{i}. **{code}** (ID: {req_id})\n   Titre: {title}\n   Texte: {text[:400]}\n\n"

                second_pass_prompt = f"""Tu es un expert en cybers√©curit√© et conformit√©.

‚ö†Ô∏è **MISSION CRITIQUE : COUVERTURE OBLIGATOIRE POUR EXIGENCES MANQUANTES**

Ces {len(batch)} exigences N'ONT PAS √âT√â COUVERTES lors de la premi√®re passe.
Tu DOIS ABSOLUMENT g√©n√©rer au moins 3 √† 5 questions pour CHACUNE d'entre elles.

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìã EXIGENCES NON COUVERTES :

{reqs_text}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üéØ **OBJECTIF** : G√©n√©rer 3-5 questions pertinentes pour CHAQUE exigence ci-dessus.

üìä FORMAT JSON OBLIGATOIRE :

```json
[
  {{
    "text": "Question pertinente (verbe √† l'infinitif ou forme interrogative)",
    "type": "yes_no|single_choice|multiple_choice|open|rating|number|date",
    "options": [],
    "help_text": "Aide contextuelle pour l'audit√©",
    "difficulty": "low|medium|high",
    "requirement_ids": ["ID_EXIGENCE_COUVERTE"],
    "ai_confidence": 0.7,
    "rationale": "Pourquoi cette question est importante",
    "tags": ["tag1", "tag2"]
  }}
]
```

‚ö†Ô∏è IMPORTANT :
- CHAQUE question DOIT avoir le requirement_id de l'exigence qu'elle couvre
- Les questions doivent v√©rifier la conformit√© de l'organisation √† l'exigence
- Varier les types de questions (yes_no, open, single_choice, etc.)

Retourne UNIQUEMENT le JSON, sans texte suppl√©mentaire."""

                # Appeler l'IA
                response = await self.http_client.call_with_retry(second_pass_prompt)

                # Parser la r√©ponse
                parsed = self.parser.parse(response)

                if parsed:
                    enriched = self.parser.coerce_and_enrich_questions(parsed)
                    all_second_pass_questions.extend(enriched)
                    logger.info(f"‚úÖ Deuxi√®me passe batch {idx}/{len(batches)}: {len(enriched)} questions")

            except Exception as e:
                logger.error(f"‚ùå Erreur deuxi√®me passe batch {idx}: {e}")
                continue

        return all_second_pass_questions

    async def _generate_batches(
        self,
        items: List[Dict[str, Any]],
        language: str,
        progress_callback = None  # Callback pour progression SSE
    ) -> List[Dict[str, Any]]:
        """
        G√©n√®re des questions par lots.

        Args:
            items: Liste d'items (exigences avec m√©tadonn√©es)
            language: Langue

        Returns:
            Liste de toutes les questions g√©n√©r√©es
        """
        all_questions: List[Dict[str, Any]] = []

        # D√©couper en batches
        batches = list(self._chunks(items, self.batch_size))
        logger.info(f"üì¶ {len(batches)} batches de {self.batch_size} max")

        # Callback initial
        if progress_callback:
            await progress_callback(0, len(batches), "started", {
                "total_requirements": len(items),
                "total_batches": len(batches),
                "batch_size": self.batch_size
            })

        for idx, batch in enumerate(batches, 1):
            logger.info(f"üîÑ Batch {idx}/{len(batches)} ({len(batch)} items)")

            # Callback avant traitement
            if progress_callback:
                await progress_callback(idx, len(batches), "processing", {
                    "batch_index": idx,
                    "batch_size": len(batch),
                    "current_questions": len(all_questions)
                })

            try:
                # Construire le prompt
                prompt = self.prompt_builder.build_user_prompt_for_requirements(
                    requirements=batch,
                    framework_name="ISO 27001"  # TODO: r√©cup√©rer depuis DB
                )

                logger.debug(f"üìù Prompt: {len(prompt)} chars")

                # Appeler l'IA
                response = await self.http_client.call_with_retry(prompt)

                # Parser la r√©ponse
                parsed = self.parser.parse(response)

                if parsed:
                    # Enrichir et normaliser
                    enriched = self.parser.coerce_and_enrich_questions(parsed)

                    # ‚úÖ Enrichir avec official_code des requirements du batch
                    # Pour permettre l'extraction du chapter
                    for q in enriched:
                        if isinstance(q, dict) and "official_code" not in q:
                            # Associer √† la premi√®re requirement du batch par d√©faut
                            # (id√©alement l'IA devrait grouper, mais fallback ici)
                            if batch and len(batch) > 0:
                                q["official_code"] = batch[0].get("official_code")

                    all_questions.extend(enriched)
                    logger.info(f"‚úÖ Batch {idx}: {len(enriched)} questions")

                    # Callback apr√®s succ√®s
                    if progress_callback:
                        await progress_callback(idx, len(batches), "batch_complete", {
                            "batch_index": idx,
                            "new_questions": len(enriched),
                            "total_questions": len(all_questions),
                            "progress_percent": int((idx / len(batches)) * 100)
                        })
                else:
                    logger.warning(f"‚ö†Ô∏è Batch {idx}: aucune question pars√©e")

            except Exception as e:
                logger.error(f"‚ùå Batch {idx} √©chou√©: {e}")
                continue

        return all_questions

    def _load_framework_and_requirements(self, framework_id: str):
        """
        Charge le framework et ses exigences depuis la DB.

        Args:
            framework_id: ID du framework

        Returns:
            Tuple (framework, requirements)

        Raises:
            ValueError: Si framework inexistant
        """
        from ...models import Framework

        if not framework_id:
            raise ValueError("framework_id requis")

        # Charger framework
        fw = self.db.query(Framework).filter_by(
            id=framework_id,
            is_active=True
        ).first()

        if not fw:
            raise ValueError(f"Framework {framework_id} non trouv√© ou inactif")

        # Charger exigences
        reqs = self.db.execute(
            text(
                """
                SELECT id, official_code, title, requirement_text, domain_id,
                       NULL::text as domain, NULL::text as subdomain
                FROM requirement
                WHERE framework_id = :fid AND is_active = true
                ORDER BY official_code NULLS LAST, created_at
                """
            ),
            {"fid": str(fw.id)},
        ).mappings().all()

        # Wrapper pour acc√®s attributs
        class RequirementWrapper:
            def __init__(self, row):
                self.id = row["id"]
                self.official_code = row["official_code"]
                self.title = row["title"]
                self.requirement_text = row["requirement_text"]
                self.domain = row["domain"]
                self.subdomain = row["subdomain"]

        requirements = [RequirementWrapper(r) for r in reqs]
        return fw, requirements

    def _fetch_control_points_for_requirements(
        self,
        requirement_ids: List[str]
    ) -> Dict[str, List[Dict]]:
        """
        R√©cup√®re les control points li√©s aux exigences.

        Args:
            requirement_ids: Liste des IDs d'exigences

        Returns:
            Mapping requirement_id ‚Üí [control_points]
        """
        if not requirement_ids:
            return {}

        rows = self.db.execute(
            text(
                """
                SELECT
                    rcp.requirement_id,
                    cp.id as cp_id,
                    cp.code as cp_code,
                    cp.name as cp_name,
                    cp.criticality_level
                FROM requirement_control_point rcp
                JOIN control_point cp ON cp.id = rcp.control_point_id
                WHERE rcp.requirement_id::text = ANY(:req_ids)
                AND cp.is_active = true
                ORDER BY rcp.requirement_id, cp.criticality_level DESC
                """
            ),
            {"req_ids": requirement_ids},
        ).mappings().all()

        # Grouper par requirement_id
        cp_map: Dict[str, List[Dict]] = {}
        for row in rows:
            req_id = str(row["requirement_id"])
            if req_id not in cp_map:
                cp_map[req_id] = []

            cp_map[req_id].append({
                "id": row["cp_id"],
                "code": row["cp_code"],
                "name": row["cp_name"],
                "criticality_level": row["criticality_level"] or "MEDIUM"
            })

        return cp_map

    @staticmethod
    def _chunks(items: List, size: int):
        """
        D√©coupe une liste en chunks de taille size.

        Args:
            items: Liste √† d√©couper
            size: Taille des chunks

        Yields:
            Chunks de taille size
        """
        for i in range(0, len(items), size):
            yield items[i:i + size]

    def _merge_unique_questions(
        self,
        q1: List[Dict[str, Any]],
        q2: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Fusionne deux listes de questions en supprimant les doublons.

        Crit√®re: Texte normalis√© (lowercase, espaces multiples supprim√©s)

        Args:
            q1: Premi√®re liste
            q2: Deuxi√®me liste

        Returns:
            Liste fusionn√©e sans doublons
        """
        def normalize_text(s: str) -> str:
            """Normalise le texte pour comparaison"""
            return " ".join((s or "").strip().lower().split())

        seen = set()
        out = []

        for q in (q1 or []):
            text = normalize_text(q.get("text", ""))
            if text and text not in seen:
                seen.add(text)
                out.append(q)

        for q in (q2 or []):
            text = normalize_text(q.get("text", ""))
            if text and text not in seen:
                seen.add(text)
                out.append(q)

        return out

    def ensure_minimum_questions(
        self,
        questions: List[Dict[str, Any]],
        requirements: List[Dict[str, Any]],
        min_count: int = 8
    ) -> List[Dict[str, Any]]:
        """
        Garantit un nombre minimum de questions via fallback algorithmique.

        Si l'IA g√©n√®re trop peu de questions, compl√®te avec des templates
        standards d√©riv√©s des exigences.

        Args:
            questions: Questions g√©n√©r√©es par l'IA
            requirements: Exigences source
            min_count: Nombre minimum requis

        Returns:
            Liste avec au moins min_count questions
        """
        if len(questions) >= min_count:
            return questions

        needed = min_count - len(questions)
        logger.info(
            f"‚ö†Ô∏è Seulement {len(questions)} questions, "
            f"fallback pour {needed} questions"
        )

        # √âchantillonner les exigences
        sample = self._pick_requirement_sample(
            requirements,
            max_reqs=min(needed * 2, 12)
        )

        # G√©n√©rer templates
        templates = self._generate_template_questions(sample)

        # Fusionner sans doublons
        completed = self._merge_unique_questions(questions, templates)

        return completed[:max(min_count, len(completed))]

    def _pick_requirement_sample(
        self,
        requirements: List[Dict[str, Any]],
        max_reqs: int = 16
    ) -> List[Dict[str, Any]]:
        """
        √âchantillonne les exigences de mani√®re d√©terministe.

        Strat√©gie: R√©partition uniforme sur toute la liste

        Args:
            requirements: Liste compl√®te
            max_reqs: Nombre max √† retourner

        Returns:
            √âchantillon repr√©sentatif
        """
        n = len(requirements)
        if n <= max_reqs:
            return list(requirements)

        step = max(1, n // max_reqs)
        sample = []
        idx = 0

        while len(sample) < max_reqs and idx < n:
            sample.append(requirements[idx])
            idx += step

        # Compl√©ter avec la fin si n√©cessaire
        i = n - 1
        while len(sample) < max_reqs and i >= 0:
            if requirements[i] not in sample:
                sample.append(requirements[i])
            i -= 1

        return sample[:max_reqs]

    def _generate_template_questions(
        self,
        requirements: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        G√©n√®re des questions templates depuis les exigences.

        5 templates par exigence:
        - Existence de proc√©dure
        - Date derni√®re revue
        - √âl√©ments de preuve
        - Niveau de mise en ≈ìuvre
        - Nombre d'incidents

        Args:
            requirements: Exigences sources

        Returns:
            Liste de questions templates
        """
        templates = []

        for r in requirements:
            title = (r.get("title") or "").strip()
            domain = r.get("domain")
            req_id = r.get("anchor_id") or r.get("id")
            short = title[:60] if title else "exigence"

            templates.extend([
                {
                    "id": str(uuid4()),
                    "text": f"Disposez-vous d'une proc√©dure formalis√©e pour ¬´ {short} ¬ª ?",
                    "type": "yes_no",
                    "options": [],
                    "help_text": "Proc√©dure document√©e, valid√©e et diffus√©e.",
                    "difficulty": "low",
                    "domain": domain,
                    "requirement_ids": [req_id] if req_id else [],
                    "ai_confidence": 0.6,
                    "rationale": "",
                    "tags": ["proc√©dure", "documentation"]
                },
                {
                    "id": str(uuid4()),
                    "text": f"Quand la derni√®re revue li√©e √† ¬´ {short} ¬ª a-t-elle √©t√© r√©alis√©e ?",
                    "type": "date",
                    "options": [],
                    "help_text": "Indiquez la date de la derni√®re revue ou audit interne.",
                    "difficulty": "medium",
                    "domain": domain,
                    "requirement_ids": [req_id] if req_id else [],
                    "ai_confidence": 0.6,
                    "rationale": "",
                    "tags": ["revue", "audit"]
                },
                {
                    "id": str(uuid4()),
                    "text": f"Quels √©l√©ments de preuve pouvez-vous fournir concernant ¬´ {short} ¬ª ?",
                    "type": "open",
                    "options": [],
                    "help_text": "Ex: proc√©dures, rapports, tickets, journaux.",
                    "difficulty": "medium",
                    "domain": domain,
                    "requirement_ids": [req_id] if req_id else [],
                    "ai_confidence": 0.6,
                    "rationale": "",
                    "tags": ["preuve", "conformit√©"]
                },
                {
                    "id": str(uuid4()),
                    "text": f"Quel est le niveau de mise en ≈ìuvre actuel pour ¬´ {short} ¬ª ?",
                    "type": "single_choice",
                    "options": [
                        "Non d√©marr√©",
                        "En cours",
                        "Partiellement en place",
                        "Mis en ≈ìuvre",
                        "Optimis√©"
                    ],
                    "help_text": "Auto-√©valuation du niveau de maturit√©.",
                    "difficulty": "low",
                    "domain": domain,
                    "requirement_ids": [req_id] if req_id else [],
                    "ai_confidence": 0.6,
                    "rationale": "",
                    "tags": ["maturit√©", "impl√©mentation"]
                },
                {
                    "id": str(uuid4()),
                    "text": f"Indiquez le nombre d'incidents li√©s √† ¬´ {short} ¬ª sur les 12 derniers mois.",
                    "type": "number",
                    "options": [],
                    "help_text": "Saisir une valeur enti√®re (0 si aucun).",
                    "difficulty": "medium",
                    "domain": domain,
                    "requirement_ids": [req_id] if req_id else [],
                    "ai_confidence": 0.6,
                    "rationale": "",
                    "tags": ["incidents", "m√©triques"]
                },
            ])

        return templates
