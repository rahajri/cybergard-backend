import asyncio
import json
import logging
import math
import re
from typing import Any, Dict, List, Optional, Tuple
from uuid import uuid4
from sqlalchemy.orm import Session
from src.models.audit import ControlPoint 
import httpx
from ..config import settings

from src.dependencies import get_deepseek_generator

logger = logging.getLogger(__name__)

# En haut du fichier
logging.basicConfig(
    level=logging.DEBUG,  # ‚úÖ Changer de INFO √† DEBUG
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)

class DeepSeekControlPointGenerator:
    """G√©n√©rateur de points de contr√¥le via DeepSeek/Ollama"""
    UUIDISH = re.compile(r"^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$", re.IGNORECASE)

    def __init__(
        self,
        db: Optional[Session] = None,
        ollama_url: str = "http://localhost:11434",
        model: str = "deepseek-v3.1:671b-cloud",
        batch_size: int = 10,
        num_ctx: int = 16384,
        num_predict: int = 4096,
        temperature: float = 0.05,
        top_p: float = 0.9,
        top_k: int = 40,
        repeat_penalty: float = 1.1,
        timeout: float = 600.0,
        max_retries: int = 3,
        ai_enabled: bool = True
    ):
        """
        Initialise le g√©n√©rateur DeepSeek.
        
        Args:
            db: Session SQLAlchemy pour d√©duplication (NOUVEAU)
            ollama_url: URL de l'API Ollama
            model: Nom du mod√®le (ex: deepseek-v3.1:671b-cloud)
            batch_size: Nombre d'exigences par batch
            num_ctx: Taille du contexte
            num_predict: Nombre max de tokens √† g√©n√©rer
            temperature: Cr√©ativit√© (0.0-1.0, d√©faut 0.05)
            top_p: Nucleus sampling
            top_k: Top-k sampling
            repeat_penalty: P√©nalit√© de r√©p√©tition
            timeout: Timeout des requ√™tes HTTP (secondes)
            max_retries: Nombre de tentatives max
            ai_enabled: Activer/d√©sactiver la g√©n√©ration IA
        """
        self.db = db
        self.existing_control_points_cache = {}  # ‚úÖ Initialisation correcte ici
        self.ollama_url = ollama_url.rstrip("/")
        self.model = model
        self.batch_size = batch_size
        self.num_ctx = num_ctx
        self.num_predict = num_predict
        self.temperature = temperature
        self.top_p = top_p
        self.top_k = top_k
        self.repeat_penalty = repeat_penalty
        self.timeout = timeout
        self.max_retries = max_retries
        self.ai_enabled = ai_enabled
        
        # ‚úÖ Initialiser le r√©sultat (pour √©viter AttributeError plus tard)
        self._result: Dict[str, Any] = {
            "control_points": [],
            "mappings": [],
            "true_uncovered_requirement_ids": []
        }
        
        if self.db:
            self._load_existing_control_points()
        
        logger.info(
            f"[PCGen] ‚úÖ Initialis√© | Model={self.model} | Batch={self.batch_size} | "
            f"Ollama={self.ollama_url} | IA={self.ai_enabled} | "
            f"Cache PCs={len(self.existing_control_points_cache)}"
        )

    # ---------------------------
    #           PUBLIC
    # ---------------------------
    # LIGNE ~90 : Apr√®s __init__, AVANT _build_system_prompt

    def _load_existing_control_points(self) -> None:
        """
        Charge tous les points de contr√¥le existants en cache.
        Permet la d√©duplication et le cross-r√©f√©rentiel.
        """
        if not self.db:
            logger.warning("[PCGen] ‚ö†Ô∏è Pas de session DB, d√©duplication d√©sactiv√©e")
            return
        
        try:
            existing_cps = self.db.query(ControlPoint).all()
            self.existing_control_points_cache = {
                cp.code: cp for cp in existing_cps if cp.code
            }
            
            logger.info(
                f"[PCGen] üíæ {len(self.existing_control_points_cache)} PCs "
                f"existants charg√©s en cache"
            )
            
            if self.existing_control_points_cache:
                first_5 = list(self.existing_control_points_cache.keys())[:5]
                logger.debug(f"[PCGen] üìã Aper√ßu cache: {first_5}")
            
        except Exception as e:
            logger.error(f"[PCGen] ‚ùå Erreur chargement cache PCs: {e}", exc_info=True)
            self.existing_control_points_cache = {}

    def _select_model_for_requirement(self, requirement: Dict[str, Any]) -> str:
        """
        S√©lectionne le mod√®le appropri√© selon la complexit√© de l'exigence.
        
        Returns:
            str: Nom du mod√®le √† utiliser
        """
        # R√©cup√©rer la config
        use_auto = settings.AI_AUTO_MODEL_SELECTION
        use_advanced_for_critical = settings.AI_USE_ADVANCED_FOR_CRITICAL
        
        if not use_auto:
            # Utiliser le mod√®le par d√©faut
            return settings.OLLAMA_MODEL
        
        # Crit√®res pour utiliser DeepSeek (mod√®le avanc√©)
        req_text = requirement.get("text", "").lower()
        req_code = requirement.get("code", "")
        
        # Cas 1 : Exigences critiques marqu√©es
        if use_advanced_for_critical:
            criticality = requirement.get("criticality", "").upper()
            if criticality in ["HIGH", "CRITICAL"]:
                logger.info(f"[PCGen] üéØ Utilisation DeepSeek pour {req_code} (criticit√©: {criticality})")
                return settings.OLLAMA_MODEL_ADVANCED
        
        # Cas 2 : Exigences techniques complexes
        complex_keywords = [
            "cryptographie", "chiffrement", "encryption",
            "architecture", "authentification multi-facteur",
            "segmentation", "micro-segmentation",
            "zero trust", "d√©tection d'intrusion"
        ]
        
        if any(keyword in req_text for keyword in complex_keywords):
            logger.info(f"[PCGen] üéØ Utilisation DeepSeek pour {req_code} (complexit√© d√©tect√©e)")
            return settings.OLLAMA_MODEL_ADVANCED
        
        # Cas 3 : Domaines sp√©cialis√©s (NIST, CIS, etc.)
        if any(framework in req_code for framework in ["NIST", "CIS", "PCI-DSS"]):
            logger.info(f"[PCGen] üéØ Utilisation DeepSeek pour {req_code} (framework sp√©cialis√©)")
            return settings.OLLAMA_MODEL_ADVANCED
        
        # Par d√©faut : Mistral (rapide et efficace)
        logger.info(f"[PCGen] ‚ö° Utilisation Mistral pour {req_code} (g√©n√©ration standard)")
        return settings.OLLAMA_MODEL


    async def _call_deepseek(
        self, 
        prompt: str, 
        model: Optional[str] = None
    ) -> str:
        """
        Appelle Ollama avec le mod√®le sp√©cifi√© ou par d√©faut.
        """
        if model is None:
            model = settings.OLLAMA_MODEL
        
        logger.info(f"[PCGen] ü§ñ Utilisation du mod√®le: {model}")
        
        # Adapter les param√®tres selon le mod√®le
        if "mistral" in model.lower():
            params = {
                "num_ctx": settings.MISTRAL_NUM_CTX,
                "num_predict": settings.MISTRAL_MAX_TOKENS,
                "temperature": settings.MISTRAL_TEMPERATURE,
                "top_p": settings.AI_TOP_P,
                "repeat_penalty": settings.AI_REPEAT_PENALTY,
            }
        else:  # DeepSeek ou autre
            params = {
                "num_ctx": settings.DEEPSEEK_NUM_CTX,
                "num_predict": settings.DEEPSEEK_MAX_TOKENS,
                "temperature": settings.DEEPSEEK_TEMPERATURE,
                "top_p": settings.AI_TOP_P,
                "repeat_penalty": settings.AI_REPEAT_PENALTY,
            }
    
        # ‚úÖ Appeler Ollama avec les bons param√®tres
        try:
            messages = [{"role": "user", "content": prompt}]
            
            payload = {
                "model": model,
                "messages": messages,
                "stream": False,
                "options": params
            }
            
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                resp = await client.post(f"{self.ollama_url}/api/chat", json=payload)
                resp.raise_for_status()
                data = resp.json()
                
                content = data.get("message", {}).get("content", "")
                
                if not content:
                    raise RuntimeError("R√©ponse vide du mod√®le")
                
                return content
                
        except Exception as e:
            logger.error(f"[PCGen] Erreur appel Ollama: {e}")
            raise RuntimeError(f"√âchec appel {model}: {str(e)}")
        

    # LIGNE 233-280 : Remplacer toute la m√©thode _call_ollama_chat

    # LIGNE 360-375 : Remplacer tout le bloc

    async def _call_ollama_chat(
        self,
        messages: List[Dict[str, str]],
        system_prompt: Optional[str] = None,
        retry_count: int = 0,
    ) -> Dict[str, Any]:
        """
        Appelle Ollama /api/chat avec gestion des retries et d√©duplication.
        """
        if retry_count >= self.max_retries:
            raise RuntimeError(f"Trop de tentatives ({self.max_retries}) ‚Äì √©chec d√©finitif.")

        # ‚úÖ CONSTRUIRE LA LISTE DES PCS EXISTANTS
        existing_pcs_summary = []
        for code, cp in self.existing_control_points_cache.items():
            existing_pcs_summary.append({
                "code": code,
                "name": cp.name or "",
                "description": (cp.description or "")[:150],
                "category": cp.category or "Non class√©"
            })
        
        existing_pcs_count = len(existing_pcs_summary)

        # ‚ö†Ô∏è IMPORTANT : Augmenter la limite pour un meilleur cross-r√©f√©rentiel
        # Avec 150 PCs * ~150 chars = ~22KB, on reste sous les limites de contexte (16K tokens)
        max_pcs_in_prompt = 100  # Augment√© de 20 √† 100 pour meilleur cross-r√©f√©rentiel

        existing_pcs_json = json.dumps(
            existing_pcs_summary[:max_pcs_in_prompt],
            indent=2,
            ensure_ascii=False
        )
        
        # ‚úÖ PROMPT SYST√àME ENRICHI AVEC D√âDUPLICATION
        enhanced_system_prompt = f"""Tu es un expert en cybers√©curit√© et conformit√©.

üéØ MISSION CRITIQUE : D√âDUPLICATION ET CROSS-R√âF√âRENTIEL

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üåê QU'EST-CE QU'UN CROSS-R√âF√âRENTIEL ?

Le CROSS-R√âF√âRENTIEL est le principe fondamental de mutualisation des contr√¥les :

üí° **Principe cl√©** :
Un M√äME Point de Contr√¥le peut satisfaire PLUSIEURS exigences de DIFF√âRENTS r√©f√©rentiels
(ISO 27001, ISO 27002, NIST, RGPD, etc.)

üéØ **Exemple concret** :
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PC-A.5.15 "Politique de contr√¥le d'acc√®s"                   ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ Satisfait simultan√©ment :                                    ‚îÇ
‚îÇ ‚úì ISO 27001:2022 ‚Üí A.5.15 (Contr√¥le d'acc√®s)               ‚îÇ
‚îÇ ‚úì ISO 27002:2022 ‚Üí 5.15 (Contr√¥le d'acc√®s)                 ‚îÇ
‚îÇ ‚úì NIST CSF ‚Üí PR.AC-1 (Gestion des identit√©s)               ‚îÇ
‚îÇ ‚úì RGPD ‚Üí Art. 32 (Limitation des acc√®s)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üìà **B√©n√©fices** :
- 1 PC impl√©ment√© = 4 exigences couvertes
- R√©duction des co√ªts d'audit (gain de 75%)
- Coh√©rence entre r√©f√©rentiels
- Simplification de la conformit√©

‚ö†Ô∏è **TON OBJECTIF PRINCIPAL** :
MAXIMISER la r√©utilisation des PCs existants pour cr√©er un maximum de liens cross-r√©f√©rentiels

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìö BASE DE CONNAISSANCE : {existing_pcs_count} PCs EXISTANTS EN BASE

{existing_pcs_json if existing_pcs_count > 0 else "‚ö†Ô∏è AUCUN PC EXISTANT - Tu peux cr√©er librement"}

{f"(Affichage limit√© √† {max_pcs_in_prompt}/{existing_pcs_count} PCs)" if existing_pcs_count > max_pcs_in_prompt else ""}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üî• PROCESSUS OBLIGATOIRE D'ANALYSE (√âTAPE PAR √âTAPE) :

Pour CHAQUE exigence que tu traites, tu DOIS suivre ce processus :

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âTAPE 1 : COMPRENDRE L'EXIGENCE                             ‚îÇ
‚îÇ ‚Üí Quel est l'objectif de s√©curit√© ?                         ‚îÇ
‚îÇ ‚Üí Quel domaine (acc√®s, chiffrement, sauvegarde, etc.) ?     ‚îÇ
‚îÇ ‚Üí Quelle action concr√®te doit √™tre mise en place ?          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âTAPE 2 : ANALYSER SYST√âMATIQUEMENT LA LISTE COMPL√àTE       ‚îÇ
‚îÇ ‚ö†Ô∏è TU DOIS PARCOURIR **TOUS** LES PCs EXISTANTS !          ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ Pour chaque PC existant, demande-toi :                       ‚îÇ
‚îÇ ‚úì Ce PC couvre-t-il le m√™me objectif de s√©curit√© ?          ‚îÇ
‚îÇ ‚úì Ce PC agit-il sur le m√™me domaine ?                       ‚îÇ
‚îÇ ‚úì Ce PC r√©pond-il √† cette nouvelle exigence ?               ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ ‚ö†Ô∏è Ne te contente PAS des 2-3 premiers PCs !                ‚îÇ
‚îÇ ‚ö†Ô∏è Parcours TOUTE la liste jusqu'√† la fin !                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âTAPE 3 : D√âCISION                                          ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ ‚úÖ SI un PC existant correspond :                           ‚îÇ
‚îÇ    ‚Üí RENVOIE sa r√©f√©rence exacte (ex: "PC-A.5.15")         ‚îÇ
‚îÇ    ‚Üí Indique "reused": true                                 ‚îÇ
‚îÇ    ‚Üí Renseigne "existing_code": "PC-A.5.15"                ‚îÇ
‚îÇ    ‚Üí Explique pourquoi dans "deduplication_rationale"      ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ ‚ùå SI AUCUN PC existant ne correspond :                     ‚îÇ
‚îÇ    ‚Üí CR√âE un nouveau PC                                     ‚îÇ
‚îÇ    ‚Üí Indique "reused": false                                ‚îÇ
‚îÇ    ‚Üí Renseigne "existing_code": null                        ‚îÇ
‚îÇ    ‚Üí Explique pourquoi dans "deduplication_rationale"      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚ö†Ô∏è R√àGLES D'UNICIT√â (CRITIQUE POUR LE CROSS-R√âF√âRENTIEL) :

1. ‚úÖ **TOUJOURS ANALYSER LA LISTE COMPL√àTE** des PCs existants avant de cr√©er
2. ‚úÖ **Un PC = Un objectif de contr√¥le UNIQUE** (ex: "Gestion des mots de passe")
3. ‚úÖ **R√âUTILISE** un PC existant si son objectif correspond (m√™me partiellement)
4. ‚úÖ **RENVOIE LA R√âF√âRENCE EXACTE** du PC existant (ex: "PC-A.5.15")
5. ‚úÖ **Un m√™me PC peut couvrir plusieurs exigences** de diff√©rents r√©f√©rentiels
6. ‚ùå **NE CR√âE PAS** un nouveau PC si un existant fait d√©j√† le travail
7. ‚ùå **NE DUPLIQUE JAMAIS** un contr√¥le qui existe d√©j√†

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üîç CRIT√àRES DE R√âUTILISATION (Sois LARGE dans ta recherche) :

‚úÖ R√âUTILISE si :
- M√™me domaine (ex: Contr√¥le d'acc√®s, Chiffrement, Sauvegarde)
- M√™me type de contr√¥le (ex: Authentification, Journalisation, Formation)
- Objectif √©quivalent ou similaire (ex: "S√©curiser les mots de passe")
- M√™me finalit√© de s√©curit√© (ex: Protection des donn√©es, Continuit√©)
- ‚ö†Ô∏è M√™me si la formulation diff√®re l√©g√®rement entre r√©f√©rentiels !

‚ùå CR√âE UNIQUEMENT si :
- AUCUN PC existant ne couvre cet objectif
- L'exigence introduit un nouveau type de contr√¥le jamais vu
- Le domaine est totalement diff√©rent de tous les PCs existants
- ‚ö†Ô∏è Tu as parcouru TOUTE la liste et rien ne correspond

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìã FORMAT DE R√âPONSE JSON OBLIGATOIRE :

‚ö†Ô∏è CHAMPS OBLIGATOIRES √Ä NE JAMAIS OMETTRE :
- criticality_level (LOW|MEDIUM|HIGH|CRITICAL)
- estimated_effort_hours (nombre entier : 2, 3, 4, 6, 8, 12, 16, 24, 40, 60, 80)

{{
  "control_points": [
    {{
      "cp_ref": "CP-DOMAINE.X.Y",
      "title": "Titre du contr√¥le",
      "description": "Description d√©taill√©e (minimum 50 mots)",
      "category": "Cat√©gorie",

      "criticality_level": "LOW|MEDIUM|HIGH|CRITICAL",  ‚Üê ‚ö†Ô∏è OBLIGATOIRE ! VARIE CETTE VALEUR !
      "estimated_effort_hours": 8,  ‚Üê ‚ö†Ô∏è OBLIGATOIRE ! VARIE CETTE VALEUR (2,3,4,6,8,12,16,24,40,60,80) !

      "ai_confidence": 0.95,
      "rationale": "Explication de la pertinence ET justification de criticality + effort",
      "requirement_ids": ["req_id_1"],

      "reused": true,
      "existing_code": "PC-XXX",
      "deduplication_rationale": "Explication d√©taill√©e"
    }}
  ],
  "mappings": [
    {{"requirement_id": "req_id_1", "cp_ref": "CP-DOMAINE.X.Y"}}
  ]
}}

‚ö†Ô∏è RAPPEL : Si tu oublies criticality_level ou estimated_effort_hours, ton JSON sera REJET√â !

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üéØ INSTRUCTIONS CRITIQUES POUR "criticality_level" ET "estimated_effort_hours" :

üö® R√àGLE ABSOLUE OBLIGATOIRE üö®

‚ùå INTERDIT : Mettre "MEDIUM" et "8" pour toutes les exigences
‚ùå INTERDIT : Utiliser toujours les m√™mes valeurs par d√©faut
‚ùå INTERDIT : Ne pas analyser la criticit√© et l'effort r√©els

‚úÖ OBLIGATOIRE : Tu DOIS varier les valeurs pour chaque exigence
‚úÖ OBLIGATOIRE : Analyser l'impact et la complexit√© de CHAQUE contr√¥le
‚úÖ OBLIGATOIRE : Justifier tes choix dans le champ "rationale"

‚ö†Ô∏è Si tu mets "MEDIUM" et "8", tu DOIS expliquer POURQUOI dans "rationale"
‚ö†Ô∏è Une base de PCs r√©aliste a une DISTRIBUTION vari√©e des criticit√©s et efforts

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìä CRITICALITY_LEVEL (Niveau de criticit√©) :

üéØ DISTRIBUTION CIBLE ATTENDUE (pour un ensemble de PCs r√©aliste) :
- 15% CRITICAL (contr√¥les critiques)
- 30% HIGH (contr√¥les importants)
- 40% MEDIUM (contr√¥les standards)
- 15% LOW (contr√¥les compl√©mentaires)

‚ö†Ô∏è VARIE les niveaux ! Ne mets PAS tout en MEDIUM !

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Analyse l'IMPACT et la SENSIBILIT√â de l'exigence :

üî¥ CRITICAL (Critique) - Exemples :
- Contr√¥le d'acc√®s aux donn√©es sensibles (RGPD, secrets)
- Chiffrement des donn√©es critiques
- Authentification multifacteur pour admins
- Sauvegarde des donn√©es critiques
- Plan de continuit√© d'activit√©
‚Üí Impact s√©curit√© MAJEUR, conformit√© OBLIGATOIRE

üü† HIGH (√âlev√©) - Exemples :
- Gestion des droits d'acc√®s
- Journalisation des √©v√©nements de s√©curit√©
- Mise √† jour des correctifs de s√©curit√©
- Contr√¥le des acc√®s physiques
- Formation √† la s√©curit√©
‚Üí Impact s√©curit√© IMPORTANT, risque significatif

üü° MEDIUM (Moyen) - Exemples :
- Politique de mots de passe standard
- Antivirus et anti-malware
- Classification des actifs
- Contr√¥le des supports amovibles
- Documentation des proc√©dures
‚Üí Impact s√©curit√© MOD√âR√â, bonne pratique standard

üü¢ LOW (Faible) - Exemples :
- Affichage des banni√®res de connexion
- Organisation des espaces de travail
- √âtiquetage des c√¢bles r√©seau
- Inventaire du mat√©riel non-critique
- Sensibilisation g√©n√©rale
‚Üí Impact s√©curit√© LIMIT√â, mesure compl√©mentaire

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚è±Ô∏è ESTIMATED_EFFORT_HOURS (Charge de travail estim√©e) :

üéØ DISTRIBUTION CIBLE ATTENDUE (pour un ensemble de PCs r√©aliste) :
- 20% ‚Üí 2-4 heures (contr√¥les simples)
- 40% ‚Üí 6-12 heures (contr√¥les standards)
- 30% ‚Üí 16-24 heures (contr√¥les complexes)
- 10% ‚Üí 40-80 heures (projets majeurs)

‚ö†Ô∏è VARIE les charges ! Ne mets PAS tout √† "8" !

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Estime le TEMPS R√âEL n√©cessaire pour impl√©menter le contr√¥le :

üïê 2-4 heures - Contr√¥les simples :
- Activation d'une fonctionnalit√© existante
- Configuration d'un param√®tre
- Cr√©ation d'un document simple
- Affichage d'une banni√®re

üïë 6-12 heures - Contr√¥les standards :
- R√©daction d'une politique compl√®te
- Configuration d'un outil de s√©curit√©
- Mise en place d'une proc√©dure
- Formation d'une √©quipe

üïì 16-24 heures - Contr√¥les complexes :
- D√©ploiement d'une solution technique
- Audit complet d'un domaine
- Mise en place d'un processus m√©tier
- Int√©gration avec syst√®mes existants

üïó 40-80 heures - Projets majeurs :
- Impl√©mentation d'un syst√®me de chiffrement complet
- Mise en place d'un SOC
- Refonte de l'architecture de s√©curit√©
- Programme de formation complet

‚ö†Ô∏è Prends en compte :
- Complexit√© technique
- Nombre de syst√®mes impact√©s
- Besoin de comp√©tences sp√©cialis√©es
- D√©pendances organisationnelles
- Phase de test et validation

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üí° EXEMPLES CONCRETS DE CROSS-R√âF√âRENTIEL :

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìå EXEMPLE 1 : R√©utilisation CROSS-R√âF√âRENTIEL (‚úÖ EXCELLENT)

Contexte : Tu traites une exigence ISO 27002
Exigence ISO 27002 : "Les mots de passe doivent respecter une complexit√© minimale"

Tu analyses la liste des PCs existants et tu trouves :
PC-A.5.1.1 "Politique de mots de passe s√©curis√©s" (cr√©√© pour ISO 27001)

‚Üí **ANALYSE** : L'objectif est identique (s√©curiser les mots de passe)
‚Üí **D√âCISION** : R√âUTILISE PC-A.5.1.1 (m√™me s'il vient d'un autre r√©f√©rentiel !)
‚Üí **R√âSULTAT** : 1 PC couvre maintenant ISO 27001 + ISO 27002 (CROSS-R√âF√âRENTIEL)

R√©ponse JSON :
{{
  "reused": true,
  "existing_code": "PC-A.5.1.1",
  "criticality_level": "HIGH",
  "estimated_effort_hours": 8,
  "deduplication_rationale": "Ce PC couvre d√©j√† la complexit√© des mots de passe. R√©utilisation cross-r√©f√©rentiel entre ISO 27001 et ISO 27002.",
  "rationale": "Criticit√© HIGH car impact important sur la s√©curit√© des acc√®s. Effort 8h pour documenter et d√©ployer la politique."
}}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìå EXEMPLE 2 : R√©utilisation avec formulation diff√©rente (‚úÖ EXCELLENT)

Contexte : Tu traites une exigence NIST
Exigence NIST CSF : "Implement multi-factor authentication for privileged accounts"

Tu analyses la liste et tu trouves :
PC-IAM.3.2 "Authentification multifacteur pour comptes √† privil√®ges" (cr√©√© pour RGPD)

‚Üí **ANALYSE** : M√™me objectif malgr√© la formulation diff√©rente (anglais vs fran√ßais)
‚Üí **D√âCISION** : R√âUTILISE PC-IAM.3.2
‚Üí **R√âSULTAT** : 1 PC couvre maintenant RGPD + NIST (CROSS-R√âF√âRENTIEL international)

R√©ponse JSON :
{{
  "reused": true,
  "existing_code": "PC-IAM.3.2",
  "criticality_level": "CRITICAL",
  "estimated_effort_hours": 16,
  "deduplication_rationale": "M√™me objectif de s√©curit√© : authentification multifacteur pour comptes privil√©gi√©s. Cross-r√©f√©rentiel RGPD-NIST.",
  "rationale": "Criticit√© CRITICAL car prot√®ge les comptes √† privil√®ges (acc√®s admin). Effort 16h pour d√©ployer MFA sur tous les comptes privil√©gi√©s et former les utilisateurs."
}}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìå EXEMPLE 3 : Cr√©ation justifi√©e (‚úÖ BON)

Contexte : Tu traites une exigence ISO 27001
Exigence ISO 27001 : "Mettre en place un syst√®me de d√©tection d'intrusion"

Tu analyses TOUTE la liste des PCs existants :
- PC-A.5.1.1 "Mots de passe" ‚Üí Non, domaine diff√©rent
- PC-A.8.2.1 "Sauvegarde" ‚Üí Non, domaine diff√©rent
- PC-A.9.1.1 "Contr√¥le d'acc√®s" ‚Üí Non, objectif diff√©rent
... (tu continues jusqu'√† la fin de la liste)

‚Üí **ANALYSE** : Aucun PC existant ne couvre la d√©tection d'intrusion
‚Üí **D√âCISION** : CR√âE un nouveau PC
‚Üí **R√âSULTAT** : Nouveau PC n√©cessaire

R√©ponse JSON :
{{
  "reused": false,
  "existing_code": null,
  "cp_ref": "PC-A.12.4.1",
  "title": "Syst√®me de d√©tection d'intrusion (IDS/IPS)",
  "criticality_level": "HIGH",
  "estimated_effort_hours": 40,
  "deduplication_rationale": "Nouveau contr√¥le n√©cessaire. Analyse compl√®te de la base : aucun PC existant ne couvre la d√©tection d'intrusion.",
  "rationale": "Criticit√© HIGH car d√©tection proactive des menaces. Effort 40h pour s√©lectionner, installer, configurer l'IDS et d√©finir les r√®gles de d√©tection."
}}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚ùå EXEMPLE 4 : Duplication INTERDITE (MAUVAIS !)

Contexte : Tu traites une exigence RGPD
Exigence RGPD : "Appliquer des r√®gles de mots de passe forts"

Tu analyses et tu trouves :
PC-A.5.1.1 "Politique de mots de passe s√©curis√©s" (cr√©√© pour ISO 27001)

‚Üí ‚ùå **ERREUR** : Cr√©er PC-RGPD.32.1 "Politique de mots de passe RGPD"
‚Üí ‚úÖ **CORRECT** : R√âUTILISER PC-A.5.1.1

**Pourquoi c'est une erreur ?**
- Duplication inutile (m√™me objectif)
- Perte du b√©n√©fice cross-r√©f√©rentiel
- Maintenance compliqu√©e (2 PCs au lieu d'1)
- Co√ªt d'audit multipli√©

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìå EXEMPLE 5 : Contr√¥le simple (‚úÖ VARIE LES VALEURS)

Contexte : Tu traites une exigence ISO 27001
Exigence ISO 27001 : "Afficher une banni√®re de connexion informant les utilisateurs"

Tu analyses TOUTE la liste ‚Üí Aucun PC existant sur les banni√®res
‚Üí **D√âCISION** : CR√âE un nouveau PC simple

R√©ponse JSON :
{{
  "reused": false,
  "existing_code": null,
  "cp_ref": "PC-A.7.2.8",
  "title": "Banni√®re d'information √† la connexion",
  "criticality_level": "LOW",
  "estimated_effort_hours": 3,
  "deduplication_rationale": "Nouveau contr√¥le. Aucun PC existant sur l'affichage de banni√®res.",
  "rationale": "Criticit√© LOW car mesure informative sans impact direct sur la s√©curit√©. Effort 3h pour cr√©er la banni√®re, la configurer sur les syst√®mes et valider l'affichage."
}}

‚ö†Ô∏è NOTE : LOW + 3h car c'est un contr√¥le simple et rapide !

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üéØ RAPPEL FINAL :

‚ö†Ô∏è AVANT de cr√©er un nouveau PC, demande-toi TOUJOURS :
"Est-ce que je peux r√©utiliser un PC existant ?"

‚úÖ Ton objectif : MAXIMISER les liens cross-r√©f√©rentiels
‚úÖ Ta mission : MINIMISER la cr√©ation de nouveaux PCs
‚úÖ Ton r√¥le : Cr√©er une base de PCs MUTUALIS√âE et EFFICACE

‚ö†Ô∏è VARIE criticality_level et estimated_effort_hours selon la R√âALIT√â de chaque contr√¥le !

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

{system_prompt if system_prompt else ""}
"""

        msgs = list(messages)
        msgs.insert(0, {"role": "system", "content": enhanced_system_prompt})

        payload = {
            "model": self.model,
            "messages": msgs,
            "stream": False,
            "options": {
                "num_ctx": self.num_ctx,
                "num_predict": self.num_predict,
                "temperature": self.temperature,
                "top_p": self.top_p,
                "top_k": self.top_k,
                "repeat_penalty": self.repeat_penalty,
            },
        }

        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                resp = await client.post(f"{self.ollama_url}/api/chat", json=payload)
                resp.raise_for_status()
                data = resp.json()
                
                # Log de debug
                raw_content = data.get("message", {}).get("content", "")
                logger.debug(f"[PCGen] üì¶ R√©ponse brute Ollama ({len(raw_content)} chars):")
                logger.debug(f"[PCGen] {raw_content[:500]}...")
                
                return data

        except httpx.TimeoutException:
            logger.warning(f"[PCGen] ‚è±Ô∏è timeout batch retry {retry_count+1}/{self.max_retries}")
            await asyncio.sleep(2)
            return await self._call_ollama_chat(messages, system_prompt, retry_count + 1)
        except Exception as e:
            logger.error(f"[PCGen] ‚ùå Ollama error: {e}")
            raise
        
    def _parse_json_blocks(self, content: str) -> List[Dict[str, Any]]:
        """
        Extrait tous les blocs JSON de la r√©ponse LLM.
        Version ultra-robuste pour DeepSeek.
        """
        import re
        
        blocks = []
        
        # 1Ô∏è‚É£ Nettoyer le contenu
        content = content.strip()
        
        # Supprimer les balises markdown
        # Patterns: ```json ... ``` ou ``` ... ```
        markdown_pattern = r'```(?:json)?\s*(.*?)\s*```'
        markdown_matches = re.findall(markdown_pattern, content, re.DOTALL)
        
        if markdown_matches:
            logger.debug(f"[PCGen] üìã {len(markdown_matches)} bloc(s) markdown trouv√©(s)")
            content = markdown_matches[0]  # Prendre le premier bloc
        
        content = content.strip()
        
        logger.debug(f"[PCGen] üßπ Contenu nettoy√©: {content[:200]}...")
        
        # 2Ô∏è‚É£ Essayer de parser directement
        try:
            data = json.loads(content)
            logger.debug(f"[PCGen] ‚úÖ JSON pars√©: {list(data.keys())}")
            blocks.append(data)
            return blocks
        except json.JSONDecodeError as e:
            logger.debug(f"[PCGen] ‚ö†Ô∏è Parsing direct √©chou√©: {e}")
        
        # 3Ô∏è‚É£ Chercher tous les objets JSON { ... }
        json_pattern = r'\{(?:[^{}]|(?:\{[^{}]*\}))*\}'
        json_matches = re.finditer(json_pattern, content, re.DOTALL)
        
        for match in json_matches:
            json_str = match.group(0)
            try:
                data = json.loads(json_str)
                logger.debug(f"[PCGen] ‚úÖ Bloc trouv√©: {list(data.keys())}")
                blocks.append(data)
            except json.JSONDecodeError:
                continue
        
        logger.debug(f"[PCGen] üì¶ Total: {len(blocks)} bloc(s) extraits")
        
        return blocks

    def _parse_batch_response(
        self, 
        raw_content: str, 
        req_batch: List[Dict[str, Any]]
    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """
        Parse la r√©ponse du LLM pour un batch.
        Retourne (control_points, mappings).
        """
        logger.debug(f"[PCGen] üîç Parsing r√©ponse batch ({len(raw_content)} chars)")
        
        blocks = self._parse_json_blocks(raw_content)
        
        if not blocks:
            logger.warning(f"[PCGen] ‚ö†Ô∏è Aucun bloc JSON trouv√© dans la r√©ponse")
            logger.debug(f"[PCGen] R√©ponse brute: {raw_content[:500]}...")
            return [], []
        
        logger.info(f"[PCGen] üì¶ {len(blocks)} blocs JSON trouv√©s")
        
        all_cps = []
        all_mappings = []
        
        for i, block in enumerate(blocks):
            logger.debug(f"[PCGen] üìã Traitement bloc {i+1}/{len(blocks)}")
            
            # Cas 1: Bloc avec "points_de_controle"
            if "points_de_controle" in block:
                cps = block["points_de_controle"]
                logger.info(f"[PCGen] ‚úÖ Trouv√© {len(cps)} PC dans bloc {i+1}")

                for cp in cps:
                    # üîç LOG AVANT NETTOYAGE pour voir ce que l'AI a retourn√©
                    logger.debug(f"[PCGen] üîç PC brut de l'AI: criticality_level={cp.get('criticality_level')}, estimated_effort_hours={cp.get('estimated_effort_hours')}")

                    # Nettoyer le PC
                    cleaned = self._clean_control_point(cp)

                    # üîç LOG APR√àS NETTOYAGE pour voir si les champs sont pr√©serv√©s
                    logger.debug(f"[PCGen] ‚úÖ PC nettoy√©: code={cleaned.get('code')}, criticality={cleaned.get('criticality')}, effort={cleaned.get('estimated_effort_hours')}")

                    all_cps.append(cleaned)

                    # Cr√©er les mappings
                    req_codes = cp.get("exigences_liees", [])
                    if isinstance(req_codes, str):
                        req_codes = [req_codes]

                    logger.debug(f"[PCGen]   PC '{cleaned.get('code')}' li√© √† {len(req_codes)} exigences")

                    for req_code in req_codes:
                        all_mappings.append({
                            "control_point_code": cleaned.get("code"),
                            "requirement_code": req_code
                        })
            
            # Cas 2: Bloc direct de PC
            elif "code" in block and "titre" in block:
                logger.info(f"[PCGen] ‚úÖ Trouv√© 1 PC direct dans bloc {i+1}")
                cleaned = self._clean_control_point(block)
                all_cps.append(cleaned)
                
                req_codes = block.get("exigences_liees", [])
                if isinstance(req_codes, str):
                    req_codes = [req_codes]
                
                for req_code in req_codes:
                    all_mappings.append({
                        "control_point_code": cleaned.get("code"),
                        "requirement_code": req_code
                    })
            
            else:
                logger.warning(f"[PCGen] ‚ö†Ô∏è Bloc {i+1} non reconnu: {list(block.keys())}")
        
        logger.info(f"[PCGen] üìä Total extrait: {len(all_cps)} PC, {len(all_mappings)} mappings")
        
        return all_cps, all_mappings

    async def generate_from_framework(
        self,
        framework: Optional[Dict[str, Any]],
        requirements: List[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """
        Point d'entr√©e depuis l'API: enveloppe un petit contexte framework.
        """
        if not self.ai_enabled:
            raise RuntimeError("IA d√©sactiv√©e ‚Äî g√©n√©ration impossible.")
        ctx = {
            "framework": {
                "id": (framework or {}).get("id"),
                "code": (framework or {}).get("code"),
                "name": (framework or {}).get("name"),
                "locale": (framework or {}).get("locale", "fr"),
            }
        }
        return await self.generate(requirements=requirements, context=ctx)

    async def generate(
        self,
        requirements: List[Dict[str, Any]],
        context: Optional[Dict[str, Any]] = None,
        db: Optional[Session] = None,
        progress_callback: Optional[Any] = None,  # Callback pour progression SSE
    ) -> Dict[str, Any]:
        """
        G√©n√®re les PC par lots, r√©pare/san√©tise les sorties IA,
        applique les fallbacks (lot + global), puis nettoie et retourne le r√©sultat.

        Args:
            progress_callback: Fonction async(batch_idx, total_batches, status, data) pour SSE
        """
        if not requirements:
            return {
                "control_points": [],
                "mappings": [],
                "true_uncovered_requirement_ids": [],
                "uncovered_after_fallback": [],
            }
        if not self.ollama_url or not self.ai_enabled:
            raise RuntimeError("IA non disponible ou d√©sactiv√©e ‚Äì g√©n√©ration impossible.")

        logger.info(f"[PCGen] lancement sur {len(requirements)} exigences (batch={self.batch_size})")

        # remise √† z√©ro du cumul
        self._result = {
            "control_points": [],
            "mappings": [],
            "true_uncovered_requirement_ids": [],
        }

        # d√©coupes en lots
        batches = list(self._chunks(requirements, self.batch_size))
        total_batches = len(batches)

        # Callback initial
        if progress_callback:
            await progress_callback(0, total_batches, "started", {
                "total_requirements": len(requirements),
                "total_batches": total_batches,
                "batch_size": self.batch_size
            })

        # boucle des lots
        for idx, batch in enumerate(batches, start=1):
            prompt = self._build_prompt_for_batch(batch, context or {})
            logger.info(f"[PCGen] ‚ñ∂Ô∏è lot {idx}/{total_batches} size={len(batch)} prompt_chars={len(prompt)}")

            # Callback avant traitement du lot
            if progress_callback:
                await progress_callback(idx, total_batches, "processing", {
                    "batch_index": idx,
                    "batch_size": len(batch),
                    "current_cps": len(self._result["control_points"])
                })

            raw = await self._call_deepseek_with_retry(prompt, self.num_predict)

            local = await self._parse_normalize_and_check(
                raw_content=raw,
                lot_requirements=batch,
                lot_idx=idx,
                lot_count=total_batches,
            )
            self._result["control_points"].extend(local["control_points"])
            self._result["mappings"].extend(local["mappings"])

            # Callback apr√®s traitement du lot
            if progress_callback:
                await progress_callback(idx, total_batches, "batch_complete", {
                    "batch_index": idx,
                    "new_cps": len(local["control_points"]),
                    "total_cps": len(self._result["control_points"]),
                    "progress_percent": int((idx / total_batches) * 100)
                })

        # d√©dup globale des PC
        cps_final, ref_alias = self._dedup_control_points(self._result["control_points"])

        # ‚úÖ LOG pour voir ce qui est dans cps_final
        logger.debug(f"[PCGen] Nombre de PC distincts apr√®s d√©duplication: {len(cps_final)}")
        logger.debug(f"[PCGen] Premiers cp_ref: {[cp.get('cp_ref') for cp in cps_final[:10]]}")

        # Propagation alias sur mappings
        mappings_final: List[Dict[str, str]] = []
        for m in self._result["mappings"]:
            rid = str(m.get("requirement_id"))
            cp_ref = m.get("cp_ref")
            if not rid or not cp_ref:
                continue
            cp_ref = ref_alias.get(cp_ref, cp_ref)
            mappings_final.append({"requirement_id": rid, "cp_ref": cp_ref})

        # couverture globale + deuxi√®me passe IA si n√©cessaire
        required_ids = {str(r.get("id")) for r in requirements if r.get("id")}
        mapped_ids = {m["requirement_id"] for m in mappings_final}
        missing_global = list(required_ids - mapped_ids)

        if missing_global:
            logger.warning(
                f"[PCGen] Couverture partielle apr√®s agr√©gation ‚Äì {len(missing_global)} exigence(s) non mapp√©e(s) "
                f"(ex: {missing_global[:5]}...)"
            )
            # on consigne les orphelines 'avant deuxi√®me passe' pour l'UI (preview)
            self._result.setdefault("true_uncovered_requirement_ids", [])
            self._result["true_uncovered_requirement_ids"].extend(missing_global)

            # ‚úÖ DEUXI√àME PASSE IA POUR LES EXIGENCES MANQUANTES
            logger.info(f"[PCGen] üîÑ Lancement de la deuxi√®me passe IA pour {len(missing_global)} exigences manquantes...")

            # Callback pour informer du d√©marrage de la deuxi√®me passe
            if progress_callback:
                await progress_callback(total_batches, total_batches, "second_pass_started", {
                    "missing_count": len(missing_global),
                    "message": f"Deuxi√®me passe IA pour {len(missing_global)} exigences non couvertes..."
                })

            # R√©cup√©rer les exigences manquantes
            missing_requirements = [r for r in requirements if str(r.get("id")) in missing_global]

            if missing_requirements:
                try:
                    # G√©n√©rer les PCs pour les exigences manquantes
                    second_pass_result = await self._generate_second_pass(missing_requirements, context)

                    if second_pass_result:
                        second_pass_cps = second_pass_result.get("control_points", [])
                        second_pass_mappings = second_pass_result.get("mappings", [])

                        logger.info(f"[PCGen] ‚úÖ Deuxi√®me passe: {len(second_pass_cps)} PC g√©n√©r√©s")

                        # Ajouter les nouveaux PCs
                        for cp in second_pass_cps:
                            # √âviter les doublons de code
                            new_ref = cp.get("cp_ref", "")
                            if new_ref and new_ref not in {c.get("cp_ref") for c in cps_final}:
                                cps_final.append(cp)

                        # Ajouter les nouveaux mappings
                        for m in second_pass_mappings:
                            rid = m.get("requirement_id")
                            cp_ref = m.get("cp_ref")
                            if rid and cp_ref:
                                mappings_final.append({"requirement_id": str(rid), "cp_ref": cp_ref})

                        # Callback pour informer de la fin de la deuxi√®me passe
                        if progress_callback:
                            await progress_callback(total_batches, total_batches, "second_pass_complete", {
                                "new_cps": len(second_pass_cps),
                                "total_cps": len(cps_final),
                                "message": f"Deuxi√®me passe termin√©e: {len(second_pass_cps)} PC suppl√©mentaires g√©n√©r√©s"
                            })

                except Exception as e:
                    logger.error(f"[PCGen] ‚ùå Erreur deuxi√®me passe IA: {e}")
                    # Ne pas g√©n√©rer de fallback automatique - laisser les exigences non couvertes
                    logger.warning(f"[PCGen] ‚ö†Ô∏è {len(missing_global)} exigences resteront non couvertes")

                    # Callback pour informer de l'erreur
                    if progress_callback:
                        await progress_callback(total_batches, total_batches, "second_pass_error", {
                            "error": str(e),
                            "message": f"Erreur deuxi√®me passe: {len(missing_global)} exigences non couvertes"
                        })

        # recalcul apr√®s deuxi√®me passe
        mapped_ids = {m["requirement_id"] for m in mappings_final}
        uncovered_after_fallback = list(required_ids - mapped_ids)

        if uncovered_after_fallback:
            logger.warning(
                f"[PCGen] ‚ö†Ô∏è ATTENTION: {len(uncovered_after_fallback)} exigences restent non couvertes apr√®s 2 passes IA. "
                f"Codes: {[reqs_index.get(rid, {}).get('official_code', rid) for rid in uncovered_after_fallback[:10]]}"
            )

        # reconstruire les exigences par CP pour l'UI
        reqs_index = {str(r.get("id")): r for r in requirements if r.get("id")}
        reqs_by_cp: Dict[str, list] = {}
        for m in mappings_final:
            ref = m["cp_ref"]
            rid = m["requirement_id"]
            reqs_by_cp.setdefault(ref, []).append(rid)

        # nettoyage qualit√© pour l'UI
        cleaned_cps: List[Dict[str, Any]] = []
        for cp in cps_final:
            ref = cp.get("cp_ref")
            if not ref:
                continue

            mapped_rids = reqs_by_cp.get(ref, [])
            if not mapped_rids:
                continue

            title = (cp.get("title") or "").strip()
            desc = (cp.get("description") or "").strip()
            dom = (cp.get("domain") or cp.get("category") or "").strip()

            # Si titre est g√©n√©rique/vide ‚Üí reconstruire depuis l'exigence
            if (not title) or (title.lower() == "domaine") or self._is_uuidish(title) or self._looks_gibberish(title):
                # Prendre la premi√®re exigence mapp√©e
                first_rid = mapped_rids[0]
                req = reqs_index.get(first_rid)
                if req:
                    title = self._make_specific_title_from_requirement(req)
                    logger.info(f"[PCGen] üîß Titre reconstruit pour {ref}: '{title}'")
                else:
                    title = f"Contr√¥le {ref}"

            # Normaliser domaine
            if not dom or self._is_uuidish(dom) or self._looks_gibberish(dom) or dom == "‚Äî":
                # Tenter de r√©cup√©rer depuis la premi√®re exigence
                first_rid = mapped_rids[0]
                req = reqs_index.get(first_rid)
                if req:
                    dom = req.get("domain") or req.get("domain_name") or "‚Äî"

            # Bornes et espaces
            title = re.sub(r"\s+", " ", title)[:180]
            desc = re.sub(r"\s+", " ", desc)[:800] if desc else ""
            dom = re.sub(r"\s+", " ", str(dom))[:80] if dom else "‚Äî"

            # AI confidence
            conf = cp.get("ai_confidence", 0.0)
            try:
                conf = float(conf)
            except Exception:
                conf = 0.0
            conf = min(max(conf, 0.0), 1.0)

            cleaned_cps.append({
                **cp,
                "title": title,
                "description": desc,
                "domain": dom,
                "ai_confidence": conf,
            })

        cps_final = cleaned_cps

        # ‚úÖ LOG final pour voir le r√©sultat
        logger.info(
            f"[PCGen] ‚úÖ termin√©: batches={total_batches}, cps={len(cps_final)}, mappings={len(mappings_final)}, "
            f"orphelines_avant={len(set(self._result['true_uncovered_requirement_ids']))}, "
            f"orphelines_apres={len(uncovered_after_fallback)}"
        )
        
        logger.debug(f"[PCGen] ‚úÖ {len(cps_final)} PC finaux pr√™ts pour insertion en BDD")
        logger.debug(f"[PCGen] Premiers PC finaux: {[cp.get('cp_ref') for cp in cps_final[:5]]}")

        # ‚úÖ‚úÖ‚úÖ FUSION DES MAPPINGS DANS LES PC ‚úÖ‚úÖ‚úÖ
        # ========== AJOUTER CES LIGNES ICI ==========
        # Regrouper les requirement_ids par cp_ref
        mappings_by_cp_ref = {}
        for m in mappings_final:
            cp_ref = m.get("cp_ref")
            req_id = m.get("requirement_id")
            if cp_ref and req_id:
                if cp_ref not in mappings_by_cp_ref:
                    mappings_by_cp_ref[cp_ref] = []
                mappings_by_cp_ref[cp_ref].append(req_id)
        
        # Ajouter mapped_requirements √† chaque PC
        for cp in cps_final:
            cp_ref = cp.get("cp_ref")
            if cp_ref:
                cp["mapped_requirements"] = mappings_by_cp_ref.get(cp_ref, [])
            else:
                cp["mapped_requirements"] = []
        
        logger.info(
            f"[PCGen] üìä Mappings fusionn√©s dans les PC: "
            f"{sum(len(mappings_by_cp_ref.get(cp.get('cp_ref'), [])) for cp in cps_final)} liaisons"
        )
        # ========== FIN FUSION ==========

        return {
            "control_points": cps_final,
            "mappings": mappings_final,
            "true_uncovered_requirement_ids": list(set(self._result.get("true_uncovered_requirement_ids", []))),
            "uncovered_after_fallback": uncovered_after_fallback,
        }
    # ---------------------------
    #       IA / PROMPTS
    # ---------------------------

    def _build_prompt_for_batch(self, requirements_batch: List[Dict[str, Any]], context: Dict[str, Any]) -> str:
        """
        Construit le prompt pour un batch d'exigences.
        Version optimis√©e pour DeepSeek avec couverture 100% obligatoire.
        """
        # Construire la liste des exigences
        reqs_text = ""
        req_ids_list = []
        for i, req in enumerate(requirements_batch, 1):
            code = req.get("official_code") or req.get("code", f"REQ-{i}")
            text = req.get("text") or req.get("description", "")
            req_id = req.get("id", f"req-{i}")
            req_ids_list.append(req_id)
            reqs_text += f"{i}. **{code}** (ID: {req_id})\n   {text}\n\n"

        prompt = f"""Tu es un expert en cybers√©curit√© et conformit√© ISO 27001/27002.

üéØ **MISSION CRITIQUE : COUVERTURE 100% OBLIGATOIRE**

Tu dois g√©n√©rer des points de contr√¥le pour les {len(requirements_batch)} exigences ci-dessous.

‚ö†Ô∏è **R√àGLE ABSOLUE** : CHAQUE exigence DOIT avoir AU MOINS UN point de contr√¥le.
- Exigences SMSI (clauses 4.x, 5.x, 6.x, 7.x, 8.x, 9.x, 10.x) = exigences organisationnelles du syst√®me de management
- Exigences Annexe A (A.x.x) = contr√¥les de s√©curit√© techniques et op√©rationnels

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìã EXIGENCES √Ä TRAITER ({len(requirements_batch)} au total) :

{reqs_text}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìä FORMAT JSON OBLIGATOIRE :

```json
{{
  "control_points": [
    {{
      "cp_ref": "CP-<CODE_EXIGENCE>-001",
      "title": "Titre actionnable du contr√¥le (verbe + objet)",
      "description": "Description d√©taill√©e de ce qui doit √™tre v√©rifi√©/audit√© (100-200 caract√®res)",
      "domain": "Cat√©gorie du contr√¥le",
      "criticality_level": "LOW|MEDIUM|HIGH|CRITICAL",
      "estimated_effort_hours": 4,
      "ai_confidence": 0.85,
      "rationale": "Justification de la pertinence du contr√¥le",
      "requirement_ids": ["<UUID_EXIGENCE>"]
    }}
  ],
  "mappings": [
    {{"requirement_id": "<UUID_EXIGENCE>", "cp_ref": "CP-<CODE>-001"}}
  ]
}}
```

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üî• **R√àGLES STRICTES** :

1. **COUVERTURE 100%** : Chaque ID d'exigence ({', '.join(req_ids_list[:3])}...) DOIT appara√Ætre dans au moins un mapping
2. **NOMMAGE** : cp_ref doit refl√©ter le code de l'exigence (ex: CP-4.1-001 pour exigence 4.1, CP-A.5.15-001 pour A.5.15)
3. **TITRE ACTIONNABLE** : Commencer par un verbe (V√©rifier, Contr√¥ler, Auditer, S'assurer, Documenter, etc.)
4. **CRITICIT√â VARI√âE** : Adapter selon l'impact (CRITICAL pour donn√©es sensibles, HIGH pour s√©curit√©, MEDIUM pour organisation, LOW pour documentation)
5. **EFFORT R√âALISTE** : 2-4h (simple), 6-12h (standard), 16-24h (complexe), 40-80h (projet)
6. **CONFIANCE IA** : 0.7-0.95 selon la clart√© de l'exigence
7. **1-2 PC MAX** par exigence (√©viter la sur-g√©n√©ration)

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üè∑Ô∏è **CAT√âGORIES DE DOMAINES** :

Pour les clauses SMSI (4-10) :
- "Contexte et p√©rim√®tre" (clause 4)
- "Leadership et engagement" (clause 5)
- "Planification et risques" (clause 6)
- "Support et ressources" (clause 7)
- "Fonctionnement op√©rationnel" (clause 8)
- "√âvaluation des performances" (clause 9)
- "Am√©lioration continue" (clause 10)

Pour l'Annexe A :
- "Politiques de s√©curit√©"
- "Organisation de la s√©curit√©"
- "S√©curit√© des ressources humaines"
- "Gestion des actifs"
- "Contr√¥le d'acc√®s"
- "Cryptographie"
- "S√©curit√© physique"
- "S√©curit√© des op√©rations"
- "S√©curit√© des communications"
- "Acquisition et d√©veloppement"
- "Relations fournisseurs"
- "Gestion des incidents"
- "Continuit√© d'activit√©"
- "Conformit√©"

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚ö†Ô∏è **VALIDATION FINALE** :

Avant de r√©pondre, v√©rifie que :
‚úÖ Chaque exigence a au moins un PC assign√©
‚úÖ Tous les IDs d'exigences apparaissent dans les mappings
‚úÖ Le JSON est valide et complet
‚úÖ Les criticit√©s sont vari√©es (pas tout en MEDIUM)
‚úÖ Les efforts sont r√©alistes et vari√©s

‚ùå **INTERDIT** :
- Ignorer une exigence
- Cr√©er des PC g√©n√©riques sans lien avec l'exigence
- Mettre la m√™me criticit√©/effort pour tout
- R√©pondre autre chose que du JSON valide

R√©ponds UNIQUEMENT avec le JSON valide et complet.
"""

        return prompt

    def _clean_control_point(self, cp: Dict[str, Any]) -> Dict[str, Any]:
        """
        Nettoie et normalise un point de contr√¥le.
        """
        # Mapper les anciens noms vers les nouveaux
        field_mapping = {
            "cp_ref": "code",
            "title": "titre",
            "domain": "domaine",
            "ai_confidence": None  # Ignorer
        }

        cleaned = {}

        for old_key, new_key in field_mapping.items():
            if new_key and old_key in cp:
                cleaned[new_key] = cp[old_key]

        # Copier les champs d√©j√† au bon format
        for key in ["code", "titre", "description", "domaine", "criticality", "criticality_level", "estimated_effort_hours", "exigences_liees"]:
            if key in cp and key not in cleaned:
                cleaned[key] = cp[key]

        # ‚ö†Ô∏è Mapper criticality_level ‚Üí criticality si n√©cessaire (pour compatibilit√© avec DB)
        if "criticality_level" in cp and "criticality" not in cleaned:
            cleaned["criticality"] = cp["criticality_level"]

        # ‚ö†Ô∏è Pr√©server estimated_effort_hours depuis la r√©ponse AI
        if "estimated_effort_hours" in cp:
            cleaned["estimated_effort_hours"] = cp["estimated_effort_hours"]

        # Valeurs par d√©faut
        if "code" not in cleaned:
            cleaned["code"] = cp.get("cp_ref", f"PC-{uuid4().hex[:8]}")

        if "titre" not in cleaned:
            cleaned["titre"] = cp.get("title", "Point de contr√¥le")

        if "description" not in cleaned:
            cleaned["description"] = cp.get("description", "")

        if "domaine" not in cleaned:
            cleaned["domaine"] = cp.get("domain", "G√©n√©ral")

        # ‚ö†Ô∏è SEULEMENT appliquer les defaults si VRAIMENT absents de la r√©ponse AI
        if "criticality" not in cleaned and "criticality_level" not in cp:
            cleaned["criticality"] = "MEDIUM"

        # ‚ö†Ô∏è Default pour estimated_effort_hours si absent
        if "estimated_effort_hours" not in cleaned:
            cleaned["estimated_effort_hours"] = 4
        
        if "exigences_liees" not in cleaned:
            # Essayer d'extraire depuis le code
            code = cleaned.get("code", "")
            if code.startswith("PC-") and "-" in code:
                parts = code.split("-")
                if len(parts) >= 2:
                    req_code = "-".join(parts[1:-1])  # Ex: PC-A.13.1.3-001 ‚Üí A.13.1.3
                    cleaned["exigences_liees"] = [req_code]
                else:
                    cleaned["exigences_liees"] = []
            else:
                cleaned["exigences_liees"] = []
        
        return cleaned

    # ---------------------------
    #      CALL DEEPSEEK
    # ---------------------------

        # ---------------------------
    #      CALL DEEPSEEK
    # ---------------------------

    async def _call_deepseek_with_retry(
        self,
        prompt: str,
        max_tokens: int = 4000,
        retry_count: int = 0
    ) -> str:
        """
        Appelle DeepSeek via Ollama avec retry automatique.
        """
        if retry_count >= self.max_retries:
            # ‚ùå ANCIEN CODE
            # raise HTTPException(
            #     status_code=503,
            #     detail=f"√âchec DeepSeek apr√®s {self.max_retries} tentatives"
            # )
            
            # ‚úÖ NOUVEAU CODE
            raise RuntimeError(
                f"√âchec DeepSeek apr√®s {self.max_retries} tentatives"
            )
        
        try:
            messages = [{"role": "user", "content": prompt}]
            
            response = await self._call_ollama_chat(
                messages=messages,
                system_prompt=None,
                retry_count=0
            )
            
            content = response.get("message", {}).get("content", "")
            
            if not content:
                logger.warning(f"[PCGen] R√©ponse vide, retry {retry_count + 1}/{self.max_retries}")
                await asyncio.sleep(2)
                return await self._call_deepseek_with_retry(prompt, max_tokens, retry_count + 1)
            
            return content
            
        except Exception as e:
            logger.error(f"[PCGen] Erreur appel DeepSeek: {e}")
            
            if retry_count < self.max_retries - 1:
                logger.warning(f"[PCGen] Retry {retry_count + 1}/{self.max_retries}")
                await asyncio.sleep(2)
                return await self._call_deepseek_with_retry(prompt, max_tokens, retry_count + 1)
            else:
                # ‚úÖ RuntimeError au lieu de HTTPException
                raise RuntimeError(f"√âchec DeepSeek: {str(e)}")


    # ---------------------------
    #    JSON: CLEAN & REPAIR
    # ---------------------------

    def _clean_json_response(self, s: str) -> str:
        if not s:
            return ""
        s = s.strip()
        s = re.sub(r"<think>.*?</think>", "", s, flags=re.DOTALL)
        s = re.sub(r"^```(?:json)?", "", s, flags=re.IGNORECASE).strip("` \n\r")
        first, last = s.find("{"), s.rfind("}")
        if first != -1 and last != -1 and last > first:
            s = s[first : last + 1]
        s = s.replace("\n", " ").replace("\r", " ")
        s = s.replace("‚Äú", '"').replace("‚Äù", '"').replace("‚Äô", "'")
        return s

    async def _repair_json_via_model(self, broken: str) -> str:
        """
        Demande au mod√®le de reformater en JSON minifi√© STRICTEMENT VALIDE selon le sch√©ma.
        """
        system = (
            "Tu es un validateur JSON. "
            "Reformate UNIQUEMENT la donn√©e ci-dessous en UN SEUL objet JSON MINIFI√â, STRICTEMENT VALIDE "
            "et CONFORME au sch√©ma: "
            '{"control_points":[{"cp_ref":"CP-001","title":"...","description":"...","domain":"..."}],'
            '"mappings":[{"requirement_id":"<RID>","cp_ref":"CP-001"}]} '
            "Aucun texte hors JSON."
        )
        user = "Donn√©e √† r√©parer (ne pas inventer, corriger seulement la syntaxe et les cl√©s): " + broken[:4000]
        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            "stream": False,
            "format": "json",
            "options": {
                "num_ctx": int(self.num_ctx),
                "num_predict": 128,
                "temperature": 0,
                "stop": ["<think>", "</think>", "```"],
            },
        }
        timeout = httpx.Timeout(connect=30.0, read=self.timeout, write=30.0, pool=30.0)
        async with httpx.AsyncClient(timeout=timeout) as client:
            resp = await client.post(f"{self.ollama_url}/api/chat", json=payload)
        resp.raise_for_status()
        data = resp.json()
        return (data.get("message") or {}).get("content", "") or ""

    async def _safe_json_extract(self, content: str) -> dict:
        """
        Extrait et parse le JSON de mani√®re robuste, m√™me si incomplet/tronqu√©.
        """
        import json
        from json_repair import repair_json
        
        # 1. Nettoyer le contenu
        cleaned = self._clean_json_response(content)
        
        # 2. Tenter le parsing direct
        try:
            return json.loads(cleaned)
        except json.JSONDecodeError:
            pass
        
        # 3. Tenter la r√©paration avec json-repair
        try:
            repaired = repair_json(cleaned)
            return json.loads(repaired)
        except Exception as e:
            logger.error(f"[PCGen] Impossible de parser/r√©parer le JSON: {e}")
            return {}

    def _desperate_sanitize_json(self, s: str) -> str:
        """
        Dernier filet de s√©curit√© :
        - isole le plus grand bloc {...}
        - corrige identifiants non quot√©s fr√©quents
        - supprime virgules finales avant } ou ]
        - remplace quotes typographiques
        - si absent des cl√©s attendues, renvoie squelette minimal
        """
        if not s:
            return '{"control_points":[],"mappings":[]}'

        s = s.replace("\r", " ").replace("\n", " ")
        s = s.replace("‚Äú", '"').replace("‚Äù", '"').replace("‚Äô", "'")

        first, last = s.find("{"), s.rfind("}")
        if first == -1 or last == -1 or last <= first:
            return '{"control_points":[],"mappings":[]}'

        s = s[first : last + 1]

        # identifiants non quot√©s -> quotes
        s = re.sub(r':\s*([A-Za-z_][A-Za-z0-9_\-]*)\s*([,}])', r':"\1"\2', s)

        # supprimer virgules tra√Ænantes
        s = re.sub(r",\s*([}\]])", r"\1", s)

        # supprimer √©ventuels code fences r√©siduels
        s = re.sub(r"^```(?:json)?", "", s, flags=re.IGNORECASE).strip("` ")

        if '"control_points"' not in s and '"mappings"' not in s and '"points"' not in s:
            return '{"control_points":[],"mappings":[]}'

        return s

    # ---------------------------
    #   SCHEMA & NORMALISATION
    # ---------------------------

    def _coalesce(self, d: Dict[str, Any], keys: List[str]) -> Any:
        for k in keys:
            if k in d and d[k] is not None:
                return d[k]
        return None

    def _coerce_schema(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Accepte des variantes (points, items, pcs, controls...) et (mappings, links...).
        Remet au sch√©ma {"control_points": [...], "mappings": [...]}.
        """
        if not isinstance(data, dict):
            return {"control_points": [], "mappings": []}

        cp_keys = ["control_points", "points", "items", "pcs", "controls", "controlPoints"]
        map_keys = ["mappings", "links", "associations", "relations", "map"]

        cps = None
        for k in cp_keys:
            v = data.get(k)
            if isinstance(v, list):
                cps = v
                break
            if isinstance(v, dict):
                cps = list(v.values())
                break

        maps = None
        for k in map_keys:
            v = data.get(k)
            if isinstance(v, list):
                maps = v
                break
            if isinstance(v, dict):
                maps = list(v.values())
                break

        if cps is None:
            cps = []
        if maps is None:
            maps = []

        out_cps: List[Dict[str, Any]] = []
        out_maps: List[Dict[str, Any]] = []

        # Certains mod√®les mettent requirement_id directement dans le CP
        for cp in cps:
            if not isinstance(cp, dict):
                continue
            rid = self._coalesce(cp, ["requirement_id", "rid", "requirement", "req", "requirementId"])
            cref = self._coalesce(cp, ["cp_ref", "ref", "id", "code", "control", "control_ref"])
            if rid and cref:
                out_maps.append({"requirement_id": str(rid), "cp_ref": str(cref)})
                for k in ["requirement_id", "rid", "requirement", "req", "requirementId"]:
                    cp.pop(k, None)
            out_cps.append(cp)

        for m in maps:
            if not isinstance(m, dict):
                continue
            mrid = self._coalesce(m, ["requirement_id", "rid", "requirement", "req", "requirementId"])
            mref = self._coalesce(m, ["cp_ref", "ref", "id", "code", "control", "control_ref"])
            if mrid and mref:
                out_maps.append({"requirement_id": str(mrid), "cp_ref": str(mref)})

        return {"control_points": out_cps, "mappings": out_maps}

    def _make_ref_from_title(self, title: str) -> str:
        base = re.sub(r"[^A-Za-z0-9]+", "-", title.strip().upper()).strip("-")
        base = base[:12] if base else f"GEN-{uuid4().hex[:6].upper()}"
        if not base.startswith("CP-"):
            base = f"CP-{base}"
        return base

    def _normalize_control_points(
        self, cps: List[Dict[str, Any]]
    ) -> Tuple[List[Dict[str, Any]], Dict[str, str]]:
        """
        Normalise les champs d'un PC, fabrique une ref si absente, borne les longueurs,
        et renvoie aussi une table d'alias (ancien_ref -> ref_normalis√©e).
        """
        out: List[Dict[str, Any]] = []
        alias_map: Dict[str, str] = {}

        def _desc_to_str(v: Any) -> str:
            if isinstance(v, str):
                return v
            if isinstance(v, dict):
                for val in v.values():
                    if isinstance(val, str) and val.strip():
                        return val
                    if isinstance(val, list):
                        for x in val:
                            if isinstance(x, str) and x.strip():
                                return x
            if isinstance(v, list):
                parts = [x.strip() for x in v if isinstance(x, str) and x.strip()]
                if parts:
                    return " ".join(parts)
            if v is None:
                return ""
            return str(v)

        for cp in cps:
            if not isinstance(cp, dict):
                continue

            # üîç LOG AVANT NORMALISATION pour voir ce que l'AI a retourn√©
            logger.debug(f"[PCGen] üîç PC brut de l'AI: criticality_level={cp.get('criticality_level')}, estimated_effort_hours={cp.get('estimated_effort_hours')}")

            raw_title = self._coalesce(cp, ["title", "name", "label"])
            if isinstance(raw_title, dict):  # parfois multi-lang
                raw_title = next((v for v in raw_title.values() if isinstance(v, str) and v.strip()), "")
            raw_desc = self._coalesce(cp, ["description", "details", "desc"])
            raw_domain = self._coalesce(cp, ["domain", "category"])
            raw_ref = self._coalesce(cp, ["cp_ref", "ref", "id", "code"])

            title = (raw_title or "").strip()
            desc = _desc_to_str(raw_desc).strip()
            dom = (raw_domain or "").strip()
            cp_ref = (str(raw_ref) if raw_ref is not None else "").strip()

            if not cp_ref and title:
                cp_ref = self._make_ref_from_title(title)

            norm_ref = cp_ref.upper().replace(" ", "-")
            norm_ref = re.sub(r"[^A-Z0-9\-]", "", norm_ref)
            if norm_ref and not norm_ref.startswith("CP-"):
                if norm_ref.startswith("CP") and not norm_ref.startswith("CP-"):
                    norm_ref = "CP-" + norm_ref[2:]
                else:
                    norm_ref = f"CP-{norm_ref}"
            if not norm_ref:
                if title:
                    norm_ref = self._make_ref_from_title(title)
                else:
                    continue

            if not title and desc:
                dot = desc.find(".")
                title = desc[:dot].strip()[:80] if dot != -1 else desc[:80].strip()
            if not title:
                title = f"Contr√¥le {norm_ref}"

            title = re.sub(r"\s+", " ", title)[:180]
            desc = re.sub(r"\s+", " ", desc)[:800] if desc else ""
            dom = re.sub(r"\s+", " ", dom)[:80] if dom else ""

            # ‚ö†Ô∏è IMPORTANT: Pr√©server TOUS les champs du PC original, pas seulement les 4 de base
            normalized_cp = dict(cp)  # Copier tous les champs originaux
            normalized_cp.update({
                "cp_ref": norm_ref,
                "title": title,
                "description": desc,
                "domain": dom
            })

            # üîç LOG APR√àS NORMALISATION pour voir si les champs sont pr√©serv√©s
            logger.debug(f"[PCGen] ‚úÖ PC normalis√©: cp_ref={norm_ref}, criticality_level={normalized_cp.get('criticality_level')}, effort={normalized_cp.get('estimated_effort_hours')}")

            out.append(normalized_cp)

            if cp_ref and cp_ref != norm_ref:
                alias_map[cp_ref] = norm_ref

        # ne pas lever si vide : l‚Äô√©tape AUTO rattrapera
        return out, alias_map

    def _dedup_control_points(
        self, cps: List[Dict[str, Any]]
    ) -> Tuple[List[Dict[str, Any]], Dict[str, str]]:
        """
        D√©duplique par cp_ref. Conserve les champs les plus ‚Äúriches‚Äù.
        """
        seen: Dict[str, Dict[str, Any]] = {}
        alias: Dict[str, str] = {}
        for cp in cps:
            ref = cp.get("cp_ref")
            if not ref:
                continue
            if ref not in seen:
                seen[ref] = dict(cp)
            else:
                s = seen[ref]
                if len(cp.get("title", "")) > len(s.get("title", "")):
                    s["title"] = cp.get("title", s.get("title", ""))
                if len(cp.get("description", "")) > len(s.get("description", "")):
                    s["description"] = cp.get("description", s.get("description", ""))
                if len(cp.get("domain", "")) > len(s.get("domain", "")):
                    s["domain"] = cp.get("domain", s.get("domain", ""))
        return list(seen.values()), alias

    # ---------------------------
    #      PARSE & CONTROLES
    # ---------------------------

    def extract_json_from_markdown(raw_response: str) -> dict:
        """
        Extrait le premier bloc JSON d'une r√©ponse markdown (```json ... ``` ou ``` ... ```).
        Si aucun bloc markdown, tente de parser tout le texte.
        Retourne un dict ou {} si √©chec.
        """
        import re
        import json

        # Cherche le bloc ```json ... ```
        match = re.search(r"```json\s*({.*?})\s*```", raw_response, re.DOTALL)
        if not match:
            # Cherche le bloc ``` ... ```
            match = re.search(r"```\s*({.*?})\s*```", raw_response, re.DOTALL)
        if match:
            json_str = match.group(1)
            try:
                return json.loads(json_str)
            except Exception:
                pass
        # Fallback‚ÄØ: tente de parser tout le texte
        try:
            return json.loads(raw_response)
        except Exception:
            return {}

    async def _parse_normalize_and_check(
        self,
        raw_content: str,
        lot_requirements: List[Dict[str, Any]],
        lot_idx: int,
        lot_count: int,
    ) -> Dict[str, Any]:
        """
        Parse la r√©ponse IA du lot, normalise, et mesure la couverture du lot.
        """
        try:
            data = await self._safe_json_extract(raw_content)
        except Exception:
            logger.error("[PCGen] JSON brut non parsable (2000 premiers chars): %s", (raw_content or "")[:2000])
            return {"control_points": [], "mappings": []}

        points = self._coerce_points_list(data)
        norm_cps, alias = self._normalize_control_points(points)

        # EXTRACTION DES MAPPINGS
        mappings: List[Dict[str, str]] = []
        
        # ‚úÖ Utiliser 'code' comme ID (car 'id' est None)
        req_by_code = {}
        for req in lot_requirements:
            req_code = str(req.get("code", ""))
            if req_code:
                req_by_code[req_code] = req_code
                # Aussi avec les 8 premiers caract√®res
                req_by_code[req_code[:8]] = req_code
        
        logger.debug(f"[PCGen] req_by_code cr√©√©: {list(req_by_code.keys())[:10]}")
        
        # 1) R√©cup√©rer depuis data["mappings"]
        raw_mappings = data.get("mappings") or data.get("links") or data.get("map") or []
        if isinstance(raw_mappings, list):
            for m in raw_mappings:
                if not isinstance(m, dict):
                    continue
                rid_partial = str(m.get("requirement_id") or m.get("rid") or m.get("req") or "").strip()
                cp_ref = str(m.get("cp_ref") or m.get("ref") or m.get("control") or "").strip()
                
                if rid_partial and cp_ref:
                    rid_full = req_by_code.get(rid_partial, rid_partial)
                    cp_ref = alias.get(cp_ref, cp_ref)
                    mappings.append({"requirement_id": rid_full, "cp_ref": cp_ref})
        
        # 2) Fallback: depuis requirement_ids dans les PC
        for cp in points or []:
            cp_ref = (cp.get("cp_ref") or cp.get("ref") or cp.get("id") or cp.get("code") or "").strip()
            if not cp_ref:
                continue
            cp_ref = alias.get(cp_ref, cp_ref)

            rids = cp.get("requirement_ids") or cp.get("requirements") or cp.get("requirement_id") or []
            if not isinstance(rids, list):
                if rids:
                    rids = [rids]
                else:
                    rids = []
            
            for rid_partial in rids:
                rid_partial_s = str(rid_partial).strip()
                if rid_partial_s:
                    rid_full = req_by_code.get(rid_partial_s, rid_partial_s)
                    
                    if not any(m["requirement_id"] == rid_full and m["cp_ref"] == cp_ref for m in mappings):
                        mappings.append({"requirement_id": rid_full, "cp_ref": cp_ref})

        if mappings:
            logger.debug(f"[PCGen] Lot {lot_idx}: {len(mappings)} mappings extraits")
        else:
            logger.warning(f"[PCGen] ‚ö†Ô∏è Lot {lot_idx}: AUCUN mapping extrait de la r√©ponse IA!")

        # ‚úÖ Couverture bas√©e sur 'code'
        batch_codes = {str(r["code"]) for r in lot_requirements if r.get("code")}
        mapped = {m["requirement_id"] for m in mappings if m.get("requirement_id") in batch_codes}
        missing = list(batch_codes - mapped)
        
        if missing:
            logger.warning(
                f"[PCGen] ‚ö†Ô∏è Lot {lot_idx}/{lot_count}: couverture partielle ‚Äî "
                f"{len(missing)}/{len(batch_codes)} exigence(s) non mapp√©e(s): {missing[:5]}"
            )
        else:
            logger.info(f"[PCGen] ‚úÖ Lot {lot_idx}/{lot_count}: 100% couvert ({len(batch_codes)} exigences)")

        return {"control_points": norm_cps, "mappings": mappings}

    def _coerce_points_list(self, data: Any) -> List[Dict[str, Any]]:
        if not isinstance(data, dict):
            return []
        # Si le dict ne contient qu'une seule cl√© et que la valeur est un dict, retourne [valeur]
        if len(data) == 1:
            v = list(data.values())[0]
            if isinstance(v, dict):
                return [v]
            if isinstance(v, list):
                return [x for x in v if isinstance(x, dict)]
        # Sinon, parcours les cl√©s candidates
        candidates = (
            "points", "control_points", "items", "controls", "data", "result", "controle_iso_27002"
        )
        for key in candidates:
            if key not in data:
                continue
            v = data.get(key)
            if isinstance(v, list):
                return [x for x in v if isinstance(x, dict)]
            if isinstance(v, dict):
                return [v]
            if isinstance(v, str):
                s = v.strip()
                if s and s[0] in "[{":
                    try:
                        obj = json.loads(s)
                        if isinstance(obj, list):
                            return [x for x in obj if isinstance(x, dict)]
                        if isinstance(obj, dict):
                            for kk in candidates:
                                vv = obj.get(kk)
                                if isinstance(vv, list):
                                    return [x for x in vv if isinstance(x, dict)]
                                if isinstance(vv, dict):
                                    return [vv]
                    except Exception:
                        pass
        return []

    async def _generate_second_pass(
        self,
        missing_requirements: List[Dict[str, Any]],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Deuxi√®me passe IA pour les exigences non couvertes.
        Utilise un prompt sp√©cifique pour garantir la couverture.
        """
        if not missing_requirements:
            return {"control_points": [], "mappings": []}

        logger.info(f"[PCGen] üîÑ Deuxi√®me passe: g√©n√©ration pour {len(missing_requirements)} exigences manquantes")

        # Construire un prompt sp√©cifique pour les exigences manquantes
        reqs_text = ""
        req_ids_list = []
        for i, req in enumerate(missing_requirements, 1):
            code = req.get("official_code") or req.get("code", f"REQ-{i}")
            text = req.get("text") or req.get("requirement_text") or req.get("description", "")
            req_id = req.get("id", f"req-{i}")
            req_ids_list.append(str(req_id))
            reqs_text += f"{i}. **{code}** (ID: {req_id})\n   {text}\n\n"

        second_pass_prompt = f"""Tu es un expert en cybers√©curit√© et conformit√© ISO 27001/27002.

‚ö†Ô∏è **MISSION CRITIQUE : COUVERTURE OBLIGATOIRE POUR EXIGENCES MANQUANTES**

Ces {len(missing_requirements)} exigences N'ONT PAS √âT√â COUVERTES lors de la premi√®re passe.
Tu DOIS ABSOLUMENT g√©n√©rer un point de contr√¥le pour CHACUNE d'entre elles.

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìã EXIGENCES NON COUVERTES :

{reqs_text}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üéØ **OBJECTIF** : G√©n√©rer 1 point de contr√¥le pertinent pour CHAQUE exigence ci-dessus.

üìä FORMAT JSON OBLIGATOIRE :

```json
{{
  "control_points": [
    {{
      "cp_ref": "CP-<CODE_EXIGENCE>-001",
      "title": "Titre actionnable (verbe + objet)",
      "description": "Description de ce qui doit √™tre v√©rifi√© (100-200 caract√®res)",
      "domain": "Cat√©gorie du contr√¥le",
      "criticality_level": "LOW|MEDIUM|HIGH|CRITICAL",
      "estimated_effort_hours": 4,
      "ai_confidence": 0.80,
      "rationale": "Justification du contr√¥le",
      "requirement_ids": ["<UUID>"]
    }}
  ],
  "mappings": [
    {{"requirement_id": "<UUID>", "cp_ref": "CP-<CODE>-001"}}
  ]
}}
```

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚ö†Ô∏è **V√âRIFICATION OBLIGATOIRE** :

IDs des exigences √† couvrir : {', '.join(req_ids_list)}

‚úÖ CHAQUE ID ci-dessus DOIT appara√Ætre dans les mappings
‚úÖ Le cp_ref doit refl√©ter le code de l'exigence (ex: CP-4.1-001, CP-5.2.a-001)
‚úÖ Le titre doit √™tre actionnable (verbe: V√©rifier, Contr√¥ler, Auditer, Documenter, etc.)

R√©ponds UNIQUEMENT avec le JSON valide et complet.
"""

        try:
            # Appeler l'IA
            response = await self._call_ollama_chat(
                messages=[{"role": "user", "content": second_pass_prompt}],
                retry_count=0
            )

            # Parser la r√©ponse
            json_str = response.get("message", {}).get("content", "")
            if not json_str:
                logger.error("[PCGen] ‚ùå Deuxi√®me passe: r√©ponse vide de l'IA")
                return {"control_points": [], "mappings": []}

            # Nettoyer et parser le JSON
            json_str = json_str.strip()
            if "```json" in json_str:
                json_str = json_str.split("```json")[1].split("```")[0].strip()
            elif "```" in json_str:
                json_str = json_str.split("```")[1].split("```")[0].strip()

            data = json.loads(json_str)

            # Extraire les PCs et mappings
            control_points = data.get("control_points", [])
            mappings = data.get("mappings", [])

            # Normaliser les PCs
            normalized_cps = []
            for cp in control_points:
                cp_ref = cp.get("cp_ref", "")
                if not cp_ref:
                    continue

                normalized_cps.append({
                    "cp_ref": cp_ref,
                    "title": cp.get("title", ""),
                    "description": cp.get("description", ""),
                    "domain": cp.get("domain", ""),
                    "criticality_level": cp.get("criticality_level", "MEDIUM"),
                    "estimated_effort_hours": cp.get("estimated_effort_hours", 8),
                    "ai_confidence": float(cp.get("ai_confidence", 0.8)),
                    "rationale": cp.get("rationale", ""),
                    "requirement_ids": cp.get("requirement_ids", []),
                })

            logger.info(f"[PCGen] ‚úÖ Deuxi√®me passe: {len(normalized_cps)} PC g√©n√©r√©s, {len(mappings)} mappings")

            # V√©rifier la couverture
            mapped_ids = {str(m.get("requirement_id")) for m in mappings}
            still_missing = set(req_ids_list) - mapped_ids
            if still_missing:
                logger.warning(f"[PCGen] ‚ö†Ô∏è Deuxi√®me passe: {len(still_missing)} exigences toujours non couvertes")

            return {"control_points": normalized_cps, "mappings": mappings}

        except json.JSONDecodeError as e:
            logger.error(f"[PCGen] ‚ùå Deuxi√®me passe: erreur parsing JSON: {e}")
            return {"control_points": [], "mappings": []}
        except Exception as e:
            logger.error(f"[PCGen] ‚ùå Deuxi√®me passe: erreur inattendue: {e}")
            return {"control_points": [], "mappings": []}

    def _build_fallback_cps(
        self,
        requirements: List[Dict[str, Any]],
        missing_ids: List[str],
        seed: int = 1,
    ) -> List[Dict[str, Any]]:
        """
        Construit des PC de secours sp√©cifiques (1 PC par exigence orpheline).
        ‚ö†Ô∏è D√âPR√âCI√â: Utiliser _generate_second_pass √† la place pour de vrais PCs g√©n√©r√©s par IA.
        """
        req_by_id = {str(r.get("id")): r for r in requirements if r.get("id")}
        out: List[Dict[str, Any]] = []
        
        for idx, rid in enumerate(missing_ids, start=seed):
            r = req_by_id.get(str(rid))
            if not r:
                continue
            
            dom = r.get("domain") or r.get("domain_name") or r.get("domain_label") or "G√©n√©ral"
            subdom = r.get("subdomain") or r.get("sub_domain") or ""
            req_title = r.get("title") or "Sans titre"
            req_code = r.get("official_code") or r.get("code") or ""
            
            # Cr√©er un titre explicite bas√© sur l'exigence
            title = f"Contr√¥le {req_code} - {req_title[:80]}" if req_code else f"Contr√¥le {dom} - {req_title[:80]}"
            
            out.append({
                "id": str(uuid4()),
                "cp_ref": f"AUTO.{dom[:3].upper()}.{idx:03d}",
                "code": f"AUTO-{dom[:3].upper()}-{idx:03d}",
                "title": title,
                "description": (
                    f"Point de contr√¥le automatique pour l'exigence '{req_title}'. "
                    f"Domaine : {dom}{(' > ' + subdom) if subdom else ''}. "
                    f"Ce contr√¥le n√©cessite une revue et un enrichissement manuel."
                ),
                "implementation_guidance": "D√©finir les modalit√©s de v√©rification et d'audit sp√©cifiques √† cette exigence.",
                "criticality": "MEDIUM",
                "ai_confidence": 0.5,
                "ai_explanation": (
                    "PC de secours cr√©√© automatiquement car l'IA n'a pas pu g√©n√©rer un contr√¥le sp√©cifique. "
                    "Une validation m√©tier est requise."
                ),
                "mapped_requirements": [str(rid)],
                "mapped_requirements_details": [r],
                "status": "pending",
                "category": dom,
                "subcategory": subdom,
                "control_family": dom,
                "estimated_effort_hours": 4,
            })
        
        return out


    # ---------------------------
    #          UTIL
    # ---------------------------

    @staticmethod
    def _chunks(lst: List[Any], n: int) -> List[List[Any]]:
        n = max(1, int(n or 1))
        return [lst[i : i + n] for i in range(0, len(lst), n)]

    def _is_uuidish(self, s: str) -> bool:
        if not s:
            return False
        # ‚úÖ Correction ici
        return bool(type(self).UUIDISH.match(s.strip()))

    def _looks_gibberish(self, s: str) -> bool:
        """
        Heuristique pour filtrer un "titre/domaine" inutilisable.
        """
        if not s:
            return True
        t = s.strip()
        if len(t) < 5:
            return True
        if self._is_uuidish(t):
            return True
        
        # Rejeter les titres g√©n√©riques interdits
        generics = [
            "point de contr√¥le",
            "point de controle",
            "contr√¥le automatique",
            "controle automatique",
            "pc automatique",
            "mesures organisationnelles",
            "mesures physiques",
            "gestion de",
            "domaine",
            "sans titre",
        ]
        t_lower = t.lower()
        for g in generics:
            if t_lower == g or t_lower.startswith(g + " "):
                return True
        
        letters = sum(c.isalpha() for c in t)
        return (letters / max(len(t), 1)) < 0.4
    
    def _make_specific_title_from_requirement(self, req: Dict[str, Any]) -> str:
        """
        Construit un titre sp√©cifique √† partir de l'exigence.
        """
        req_title = (req.get("title") or "").strip()
        req_code = (req.get("official_code") or req.get("code") or "").strip()
        domain = (req.get("domain") or req.get("domain_name") or "").strip()
        subdomain = (req.get("subdomain") or req.get("subdomain_name") or "").strip()
        
        # Extraire les verbes d'action de l'exigence
        action_verbs = [
            "v√©rifier", "contr√¥ler", "auditer", "s'assurer", "valider", 
            "surveiller", "documenter", "identifier", "√©valuer", "tester",
            "mettre en place", "impl√©menter", "maintenir", "r√©viser"
        ]
        
        title_lower = req_title.lower()
        verb = "Contr√¥ler"
        for v in action_verbs:
            if v in title_lower:
                verb = v.capitalize()
                break
        
        # Construire un titre actionnable
        if len(req_title) > 80:
            # Trouver une coupure naturelle
            short = req_title[:77]
            last_space = short.rfind(" ")
            if last_space > 40:
                short = short[:last_space]
            title = f"{verb} {short}..."
        else:
            # Reformuler pour commencer par un verbe
            if req_title.lower().startswith(("la ", "le ", "les ", "l'")):
                # "La gestion des..." ‚Üí "Contr√¥ler la gestion des..."
                title = f"{verb} {req_title.lower()}"
            else:
                title = f"{verb} : {req_title}"
        
        # Ajouter le code si disponible
        if req_code:
            title = f"[{req_code}] {title}"
        
        return title[:180]

