"""
Service de gÃ©nÃ©ration de plans d'action IA.

Ce service orchestre les 4 phases de gÃ©nÃ©ration :
1. Analyse des rÃ©ponses du questionnaire
2. DÃ©tection des non-conformitÃ©s et risques
3. GÃ©nÃ©ration des actions correctives avec IA
4. Assignation automatique des responsables
"""

import logging
from typing import List, Dict, Any, Optional, Tuple
from uuid import UUID
from datetime import datetime, timezone
from sqlalchemy.orm import Session
from sqlalchemy import select, and_, text
import json
import httpx
import os
from pathlib import Path

from src.models.action_plan import (
    ActionPlan,
    ActionPlanItem,
    ActionPlanStatus,
    ActionPlanItemStatus,
    ActionSeverity,
    ActionPriority,
    AssignmentMethod
)
from src.schemas.action_plan import GenerationProgress, PhaseStatus

logger = logging.getLogger(__name__)


class ActionPlanService:
    """Service de gÃ©nÃ©ration de plans d'action avec IA."""

    def __init__(self, ollama_base_url: str = "http://localhost:11434"):
        """
        Initialise le service.

        Args:
            ollama_base_url: URL de base d'Ollama pour les appels IA
        """
        self.ollama_base_url = ollama_base_url
        self.client = httpx.AsyncClient(timeout=120.0)

        # Charger les prompts depuis les fichiers
        self.prompts_dir = Path(__file__).parent.parent.parent / "prompts"
        self.system_prompt = self._load_prompt("00_system_prompt.txt")
        self.analysis_prompt = self._load_prompt("02_analysis_prompt.txt")
        self.action_plan_prompt = self._load_prompt("03_action_plan_prompt.txt")

    def _load_prompt(self, filename: str) -> str:
        """
        Charge un prompt depuis un fichier.

        Args:
            filename: Nom du fichier prompt

        Returns:
            Contenu du prompt
        """
        prompt_path = self.prompts_dir / filename
        try:
            with open(prompt_path, 'r', encoding='utf-8') as f:
                content = f.read()
                logger.info(f"âœ… Prompt chargÃ©: {filename}")
                return content
        except FileNotFoundError:
            logger.error(f"âŒ Fichier prompt introuvable: {prompt_path}")
            raise
        except Exception as e:
            logger.error(f"âŒ Erreur chargement prompt {filename}: {e}")
            raise

    async def generate_action_plan(
        self,
        campaign_id: UUID,
        tenant_id: UUID,
        db: Session,
        progress_callback: Optional[callable] = None
    ) -> ActionPlan:
        """
        GÃ©nÃ¨re un plan d'action complet avec les 4 phases IA.

        IMPORTANT: GÃ©nÃ¨re TOUT EN MÃ‰MOIRE puis crÃ©e ActionPlan en DRAFT Ã  la fin.
        Rien n'est enregistrÃ© en base de donnÃ©es avant la fin des 4 phases.

        Args:
            campaign_id: ID de la campagne
            tenant_id: ID du tenant (pour l'ActionPlan)
            db: Session database
            progress_callback: Fonction callback pour envoyer progression SSE

        Returns:
            ActionPlan crÃ©Ã© en status=DRAFT avec tous les items
        """
        logger.info(f"ğŸš€ DÃ©marrage gÃ©nÃ©ration plan d'action pour campagne {campaign_id}")

        # Pas d'ActionPlan existant - gÃ©nÃ©ration en mÃ©moire uniquement

        try:
            # ==================== PHASE 1: ANALYSE DES RÃ‰PONSES ====================
            await self._update_progress(
                action_plan, db,
                current_phase=1,
                phase1_status=PhaseStatus.IN_PROGRESS,
                progress_callback=progress_callback
            )

            analyzed_responses = await self.phase1_analyze_responses(
                campaign_id, db, action_plan, progress_callback
            )

            await self._update_progress(
                action_plan, db,
                phase1_status=PhaseStatus.COMPLETED,
                questions_analyzed=len(analyzed_responses),
                progress_callback=progress_callback
            )

            logger.info(f"âœ… Phase 1 terminÃ©e : {len(analyzed_responses)} rÃ©ponses analysÃ©es")

            # ==================== PHASE 2: DÃ‰TECTION NC ET RISQUES ====================
            await self._update_progress(
                action_plan, db,
                current_phase=2,
                phase2_status=PhaseStatus.IN_PROGRESS,
                progress_callback=progress_callback
            )

            nonconformities = await self.phase2_detect_nonconformities(
                analyzed_responses, db, action_plan, progress_callback
            )

            await self._update_progress(
                action_plan, db,
                phase2_status=PhaseStatus.COMPLETED,
                non_conformities_found=len(nonconformities),
                progress_callback=progress_callback
            )

            logger.info(f"âœ… Phase 2 terminÃ©e : {len(nonconformities)} NC dÃ©tectÃ©es")

            # ==================== PHASE 2.5: RE-VALIDATION 2-PASS ====================
            await self._update_progress(
                action_plan, db,
                current_phase=2,
                progress_callback=progress_callback
            )

            nonconformities = await self.phase2_5_revalidate_analysis(
                nonconformities, db, action_plan, progress_callback
            )

            logger.info(f"âœ… Phase 2.5 terminÃ©e : {len(nonconformities)} NC validÃ©es")

            # ==================== PHASE 3: GÃ‰NÃ‰RATION ACTIONS IA ====================
            await self._update_progress(
                action_plan, db,
                current_phase=3,
                phase3_status=PhaseStatus.IN_PROGRESS,
                progress_callback=progress_callback
            )

            action_items = await self.phase3_generate_actions(
                nonconformities, action_plan_id, db, action_plan, progress_callback
            )

            await self._update_progress(
                action_plan, db,
                phase3_status=PhaseStatus.COMPLETED,
                actions_generated=len(action_items),
                progress_callback=progress_callback
            )

            logger.info(f"âœ… Phase 3 terminÃ©e : {len(action_items)} actions gÃ©nÃ©rÃ©es")

            # ==================== PHASE 4: ASSIGNATION AUTOMATIQUE ====================
            await self._update_progress(
                action_plan, db,
                current_phase=4,
                phase4_status=PhaseStatus.IN_PROGRESS,
                progress_callback=progress_callback
            )

            assigned_items = await self.phase4_auto_assign(
                action_items, campaign_id, db, action_plan, progress_callback
            )

            await self._update_progress(
                action_plan, db,
                phase4_status=PhaseStatus.COMPLETED,
                actions_assigned=len(assigned_items),
                progress_callback=progress_callback
            )

            logger.info(f"âœ… Phase 4 terminÃ©e : {len(assigned_items)} actions assignÃ©es")

            # ==================== FINALISATION ====================
            # Calculer statistiques
            stats = self._calculate_statistics(assigned_items)
            action_plan.total_actions = stats['total']
            action_plan.critical_count = stats['critical']
            action_plan.major_count = stats['major']
            action_plan.minor_count = stats['minor']
            action_plan.info_count = stats['info']
            action_plan.overall_risk_level = stats['overall_risk']
            action_plan.dominant_language = 'fr'
            action_plan.status = ActionPlanStatus.DRAFT
            action_plan.generated_at = datetime.now(timezone.utc)

            db.commit()
            db.refresh(action_plan)

            logger.info(f"ğŸ‰ Plan d'action gÃ©nÃ©rÃ© avec succÃ¨s : {stats['total']} actions")
            return action_plan

        except Exception as e:
            logger.error(f"âŒ Erreur lors de la gÃ©nÃ©ration : {str(e)}", exc_info=True)
            action_plan.status = ActionPlanStatus.NOT_STARTED
            action_plan.generation_progress = {
                "error_message": str(e)
            }
            db.commit()
            raise

    # ==================== PHASE 1: ANALYSE DES RÃ‰PONSES ====================

    async def phase1_analyze_responses(
        self,
        campaign_id: UUID,
        db: Session,
        action_plan: ActionPlan,
        progress_callback: Optional[callable] = None
    ) -> List[Dict[str, Any]]:
        """
        Phase 1 : Collecte et analyse de toutes les rÃ©ponses du questionnaire.

        Returns:
            Liste des rÃ©ponses avec mÃ©tadonnÃ©es (question, conformitÃ©, risque, etc.)
        """
        logger.info("ğŸ“‹ Phase 1 : Analyse des rÃ©ponses...")

        # RequÃªte pour rÃ©cupÃ©rer toutes les rÃ©ponses avec contexte
        query = text("""
            SELECT
                qr.id as response_id,
                qr.question_id,
                qr.answer_value,
                q.question_text,
                q.response_type,
                req.id as requirement_id,
                req.official_code as requirement_code,
                req.title as requirement_title,
                req.requirement_text,
                d.title as domain_name,
                d.code as domain_code
            FROM question_answer qr
            JOIN question q ON qr.question_id = q.id
            LEFT JOIN requirement req ON q.requirement_id = req.id
            LEFT JOIN domain d ON req.domain_id = d.id
            WHERE qr.campaign_id = CAST(:campaign_id AS uuid)
            ORDER BY d.title, req.official_code
        """)

        result = db.execute(query, {"campaign_id": str(campaign_id)})
        rows = result.fetchall()

        analyzed = []
        total = len(rows)

        for idx, row in enumerate(rows):
            analyzed.append({
                "response_id": row.response_id,
                "question_id": row.question_id,
                "question_text": row.question_text,
                "response_type": row.response_type,
                "answer_value": row.answer_value,
                # Note: conformite, risque, justification will be added by AI in Phase 2
                "requirement_id": row.requirement_id,
                "requirement_code": row.requirement_code,
                "requirement_title": row.requirement_title,
                "requirement_text": row.requirement_text,
                "domain_name": row.domain_name,
                "domain_code": row.domain_code,
            })

            # Envoyer progression tous les 10 items
            if progress_callback and (idx + 1) % 10 == 0:
                await self._update_progress(
                    action_plan, db,
                    questions_analyzed=idx + 1,
                    total_questions=total,
                    progress_callback=progress_callback
                )

        # Mise Ã  jour finale
        if progress_callback:
            await self._update_progress(
                action_plan, db,
                questions_analyzed=total,
                total_questions=total,
                progress_callback=progress_callback
            )

        return analyzed

    # ==================== PHASE 2: ANALYSE IA DES RÃ‰PONSES ====================

    async def phase2_detect_nonconformities(
        self,
        analyzed_responses: List[Dict[str, Any]],
        db: Session,
        action_plan: ActionPlan,
        progress_callback: Optional[callable] = None
    ) -> List[Dict[str, Any]]:
        """
        Phase 2 : Analyse IA de TOUTES les rÃ©ponses avec le prompt 02_analysis_prompt.

        L'IA analyse chaque question et dÃ©termine :
        - conformite : conforme | partiel | non_conforme | non_applicable
        - risque : faible | moyen | Ã©levÃ© | critique
        - action_requise : true/false
        - justification : explication courte

        Returns:
            Liste des questions avec analyse IA enrichie
        """
        logger.info("ğŸ¤– Phase 2 : Analyse IA des rÃ©ponses...")

        # RÃ©cupÃ©rer infos campagne pour contexte
        campaign_id = action_plan.campaign_id
        campaign_query = text("""
            SELECT c.title, c.description, f.name as framework_name
            FROM campaign c
            LEFT JOIN questionnaire q ON c.questionnaire_id = q.id
            LEFT JOIN framework f ON q.framework_id = f.id
            WHERE c.id = CAST(:campaign_id AS uuid)
        """)
        campaign_info = db.execute(campaign_query, {"campaign_id": str(campaign_id)}).fetchone()

        # PrÃ©parer donnÃ©es pour l'IA
        campaign_json = json.dumps({
            "title": campaign_info.title if campaign_info else "Campagne d'audit",
            "framework": campaign_info.framework_name if campaign_info else "ISO 27001",
            "description": campaign_info.description if campaign_info else ""
        }, ensure_ascii=False, indent=2)

        questions_json = json.dumps([
            {
                "question_id": str(r['question_id']),
                "question_text": r['question_text'],
                "answer_value": r['answer_value'],
                "requirement_code": r['requirement_code'],
                "requirement_title": r['requirement_title']
            }
            for r in analyzed_responses
        ], ensure_ascii=False, indent=2)

        # Formater le prompt avec variables
        analysis_prompt_filled = self.analysis_prompt.format(
            language="FR",  # TODO: dÃ©tecter langue du questionnaire
            campaign_json=campaign_json,
            questions_json=questions_json
        )

        # Appel IA pour analyse globale
        try:
            logger.info(f"ğŸ“¡ Appel IA pour analyser {len(analyzed_responses)} questions...")

            # Informer l'utilisateur
            if progress_callback:
                await self._update_progress(
                    action_plan, db,
                    phase2_status=PhaseStatus.IN_PROGRESS,
                    progress_callback=progress_callback
                )

            response = await self.client.post(
                f"{self.ollama_base_url}/api/generate",
                json={
                    "model": "deepseek-v3.1:671b-cloud",
                    "system": self.system_prompt,
                    "prompt": analysis_prompt_filled,
                    "stream": False,
                    "format": "json"
                },
                timeout=120.0
            )

            if response.status_code == 200:
                result = response.json()

                # Informer l'utilisateur
                if progress_callback:
                    await self._update_progress(
                        action_plan, db,
                        progress_callback=progress_callback
                    )

                ai_analysis = json.loads(result['response'])

                # Enrichir analyzed_responses avec l'analyse IA
                questions_analysis = {
                    qa['question_id']: qa
                    for qa in ai_analysis.get('questions_analysis', [])
                }

                enriched = []
                for r in analyzed_responses:
                    qid = str(r['question_id'])
                    if qid in questions_analysis:
                        ia = questions_analysis[qid]
                        r['conformite'] = ia.get('conformite', r.get('conformite'))
                        r['risque'] = ia.get('risque', r.get('risque'))
                        r['action_requise'] = ia.get('action_requise', False)
                        r['justification'] = ia.get('justification', r.get('justification'))
                    enriched.append(r)

                # Filtrer pour garder uniquement celles nÃ©cessitant action
                nonconformities = [r for r in enriched if r.get('action_requise', False)]

                logger.info(f"âœ… Analyse IA terminÃ©e : {len(nonconformities)}/{len(analyzed_responses)} nÃ©cessitent une action")
                return nonconformities

            else:
                logger.warning(f"âš ï¸ Erreur IA analyse: {response.status_code}, fallback rÃ¨gles")
                return self._fallback_detect_nc(analyzed_responses)

        except Exception as e:
            logger.error(f"âŒ Erreur appel IA Phase 2: {str(e)}")
            return self._fallback_detect_nc(analyzed_responses)

    def _fallback_detect_nc(self, responses: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Fallback : dÃ©tection NC par rÃ¨gles si IA indisponible.

        Returns:
            NC dÃ©tectÃ©es par rÃ¨gles simples
        """
        nonconformities = []
        for response in responses:
            # Si conformite/risque pas encore dÃ©finis, utiliser rÃ¨gle basique sur answer_value
            answer_value = response.get('answer_value')

            # DÃ©tecter NC selon type de rÃ©ponse
            if isinstance(answer_value, bool) and answer_value is False:
                response['conformite'] = 'non_conforme'
                response['risque'] = 'moyen'
                response['action_requise'] = True
                response['justification'] = "RÃ©ponse nÃ©gative dÃ©tectÃ©e (analyse manuelle nÃ©cessaire)"
                nonconformities.append(response)
            elif isinstance(answer_value, str) and answer_value.lower() in ['non', 'no', 'non applicable']:
                response['conformite'] = 'non_conforme' if 'non' in answer_value.lower() else 'non_applicable'
                response['risque'] = 'moyen' if 'non' in answer_value.lower() else 'faible'
                response['action_requise'] = 'non' in answer_value.lower()
                response['justification'] = f"RÃ©ponse '{answer_value}' nÃ©cessite vÃ©rification"
                if response['action_requise']:
                    nonconformities.append(response)

        logger.info(f"ğŸ” Fallback : {len(nonconformities)} NC dÃ©tectÃ©es sur {len(responses)} rÃ©ponses")
        return nonconformities

    # ==================== PHASE 2.5: RE-VALIDATION 2-PASS ====================

    async def phase2_5_revalidate_analysis(
        self,
        nonconformities: List[Dict[str, Any]],
        db: Session,
        action_plan: ActionPlan,
        progress_callback: Optional[callable] = None
    ) -> List[Dict[str, Any]]:
        """
        Phase 2.5 : Re-validation 2-pass des non-conformitÃ©s dÃ©tectÃ©es.

        Cette phase effectue une seconde analyse IA sur les NC dÃ©tectÃ©es en Phase 2
        pour confirmer/affiner les niveaux de conformitÃ© et risque, garantissant
        une analyse plus robuste (comme pour la gÃ©nÃ©ration de questions).

        Args:
            nonconformities: NC dÃ©tectÃ©es en Phase 2
            db: Session database
            action_plan: ActionPlan en cours
            progress_callback: Callback pour SSE

        Returns:
            NC validÃ©es et potentiellement affinÃ©es
        """
        logger.info(f"ğŸ” Phase 2.5 : Re-validation 2-pass de {len(nonconformities)} NC...")

        if not nonconformities:
            logger.info("âœ… Aucune NC Ã  re-valider")
            return []

        # Informer l'utilisateur
        if progress_callback:
            await self._update_progress(
                action_plan, db,
                progress_callback=progress_callback
            )

        # PrÃ©parer contexte campagne
        campaign_id = action_plan.campaign_id
        campaign_query = text("""
            SELECT c.title, c.description, f.name as framework_name
            FROM campaign c
            LEFT JOIN questionnaire q ON c.questionnaire_id = q.id
            LEFT JOIN framework f ON q.framework_id = f.id
            WHERE c.id = CAST(:campaign_id AS uuid)
        """)
        campaign_info = db.execute(campaign_query, {"campaign_id": str(campaign_id)}).fetchone()

        campaign_json = json.dumps({
            "title": campaign_info.title if campaign_info else "Campagne d'audit",
            "framework": campaign_info.framework_name if campaign_info else "ISO 27001",
            "description": campaign_info.description if campaign_info else ""
        }, ensure_ascii=False, indent=2)

        # PrÃ©parer donnÃ©es pour re-validation
        questions_json = json.dumps([
            {
                "question_id": str(nc['question_id']),
                "question_text": nc['question_text'],
                "answer_value": nc['answer_value'],
                "answer_comment": nc.get('answer_comment', ''),
                "current_conformite": nc.get('conformite'),
                "current_risque": nc.get('risque'),
                "current_justification": nc.get('justification')
            }
            for nc in nonconformities
        ], ensure_ascii=False, indent=2)

        # Prompt de re-validation (utilise 02_analysis_prompt avec contexte enrichi)
        revalidation_prompt = self.analysis_prompt.format(
            language="FR",
            campaign_json=campaign_json,
            questions_json=questions_json
        )

        # Appel IA pour re-validation
        try:
            logger.info(f"ğŸ“¡ Appel IA pour re-valider {len(nonconformities)} NC...")

            # Informer l'utilisateur
            if progress_callback:
                await self._update_progress(
                    action_plan, db,
                    progress_callback=progress_callback
                )

            response = await self.client.post(
                f"{self.ollama_base_url}/api/generate",
                json={
                    "model": "deepseek-v3.1:671b-cloud",
                    "system": self.system_prompt,
                    "prompt": revalidation_prompt,
                    "stream": False,
                    "format": "json"
                },
                timeout=120.0
            )

            if response.status_code == 200:
                result = response.json()

                # Informer l'utilisateur
                if progress_callback:
                    await self._update_progress(
                        action_plan, db,
                        progress_callback=progress_callback
                    )

                ai_revalidation = json.loads(result['response'])

                # CrÃ©er index pour accÃ¨s rapide
                revalidation_index = {
                    qa['question_id']: qa
                    for qa in ai_revalidation.get('questions_analysis', [])
                }

                # Consolider avec rÃ©sultats Phase 2
                validated_nc = []
                adjusted_count = 0

                for nc in nonconformities:
                    qid = str(nc['question_id'])

                    if qid in revalidation_index:
                        revalidated = revalidation_index[qid]

                        # Conserver le plus conservateur entre Phase 2 et re-validation
                        original_conformite = nc.get('conformite')
                        revalidated_conformite = revalidated.get('conformite')

                        original_risque = nc.get('risque')
                        revalidated_risque = revalidated.get('risque')

                        # PrioritÃ© conformitÃ© : non_conforme > partiel > conforme
                        conformite_priority = {'non_conforme': 3, 'partiel': 2, 'conforme': 1, 'non_applicable': 0}
                        final_conformite = max(
                            [original_conformite, revalidated_conformite],
                            key=lambda c: conformite_priority.get(c, 0)
                        )

                        # PrioritÃ© risque : critique > Ã©levÃ© > moyen > faible
                        risque_priority = {'critique': 4, 'Ã©levÃ©': 3, 'moyen': 2, 'faible': 1}
                        final_risque = max(
                            [original_risque, revalidated_risque],
                            key=lambda r: risque_priority.get(r, 0)
                        )

                        # VÃ©rifier si ajustement
                        if final_conformite != original_conformite or final_risque != original_risque:
                            adjusted_count += 1
                            logger.info(
                                f"ğŸ”„ Ajustement Q{qid}: "
                                f"conformitÃ© {original_conformite}â†’{final_conformite}, "
                                f"risque {original_risque}â†’{final_risque}"
                            )

                        # Mettre Ã  jour NC avec valeurs validÃ©es
                        nc['conformite'] = final_conformite
                        nc['risque'] = final_risque
                        nc['justification'] = revalidated.get('justification', nc.get('justification'))
                        nc['action_requise'] = revalidated.get('action_requise', True)

                        # Garder uniquement si action toujours requise
                        if nc['action_requise']:
                            validated_nc.append(nc)
                    else:
                        # Pas de re-validation IA, garder original
                        validated_nc.append(nc)

                # Informer l'utilisateur
                if progress_callback:
                    await self._update_progress(
                        action_plan, db,
                        progress_callback=progress_callback
                    )

                logger.info(
                    f"âœ… Re-validation terminÃ©e : {len(validated_nc)}/{len(nonconformities)} NC confirmÃ©es, "
                    f"{adjusted_count} ajustÃ©es, {len(nonconformities) - len(validated_nc)} rejetÃ©es"
                )
                return validated_nc

            else:
                logger.warning(f"âš ï¸ Erreur IA re-validation: {response.status_code}, NC Phase 2 conservÃ©es")

                # Informer l'utilisateur
                if progress_callback:
                    await self._update_progress(
                        action_plan, db,
                        progress_callback=progress_callback
                    )

                return nonconformities

        except Exception as e:
            logger.error(f"âŒ Erreur appel IA Phase 2.5: {str(e)}, NC Phase 2 conservÃ©es")

            # Informer l'utilisateur
            if progress_callback:
                await self._update_progress(
                    action_plan, db,
                    progress_callback=progress_callback
                )

            return nonconformities

    # ==================== PHASE 3: GÃ‰NÃ‰RATION PLAN D'ACTION COMPLET ====================

    async def phase3_generate_actions(
        self,
        nonconformities: List[Dict[str, Any]],
        action_plan_id: UUID,
        db: Session,
        action_plan: ActionPlan,
        progress_callback: Optional[callable] = None
    ) -> List[ActionPlanItem]:
        """
        Phase 3 : GÃ©nÃ¨re le plan d'action complet avec regroupement IA.

        Utilise le prompt 03_action_plan_prompt pour :
        - Regrouper les NC similaires en actions cohÃ©rentes
        - GÃ©nÃ©rer action_plan_summary (titre, risque global, justification)
        - GÃ©nÃ©rer actions structurÃ©es avec justifications complÃ¨tes

        Returns:
            Liste des ActionPlanItem crÃ©Ã©s avec regroupement
        """
        logger.info("ğŸ¤– Phase 3 : GÃ©nÃ©ration plan d'action complet avec IA...")

        # RÃ©cupÃ©rer infos campagne
        campaign_id = action_plan.campaign_id
        campaign_query = text("""
            SELECT c.title, c.description, c.tenant_id, f.name as framework_name,
                   o.name as org_name
            FROM campaign c
            LEFT JOIN questionnaire q ON c.questionnaire_id = q.id
            LEFT JOIN framework f ON q.framework_id = f.id
            LEFT JOIN organization o ON c.tenant_id = o.id
            WHERE c.id = CAST(:campaign_id AS uuid)
        """)
        campaign_info = db.execute(campaign_query, {"campaign_id": str(campaign_id)}).fetchone()

        # RÃ©cupÃ©rer rÃ´les autorisÃ©s depuis la table role
        roles_query = text("""
            SELECT code, label FROM role
            WHERE tenant_id = CAST(:tenant_id AS uuid) OR tenant_id IS NULL
            ORDER BY label
        """)
        roles_result = db.execute(roles_query, {
            "tenant_id": str(campaign_info.tenant_id) if campaign_info else None
        })
        allowed_roles = [row.code for row in roles_result]

        # PrÃ©parer contexte campagne
        campaign_json = json.dumps({
            "title": campaign_info.title if campaign_info else "Campagne d'audit",
            "organization": campaign_info.org_name if campaign_info else "Organisation",
            "framework": campaign_info.framework_name if campaign_info else "ISO 27001",
            "description": campaign_info.description if campaign_info else ""
        }, ensure_ascii=False, indent=2)

        # PrÃ©parer liste rÃ´les
        allowed_roles_json = json.dumps(allowed_roles, ensure_ascii=False, indent=2)

        # PrÃ©parer non-conformitÃ©s
        non_conformities_json = json.dumps([
            {
                "question_id": str(nc['question_id']),
                "question_text": nc['question_text'],
                "answer_value": nc['answer_value'],
                "conformite": nc.get('conformite'),
                "risque": nc.get('risque'),
                "justification": nc.get('justification'),
                "requirement_code": nc.get('requirement_code'),
                "requirement_title": nc.get('requirement_title'),
                "domain_name": nc.get('domain_name')
            }
            for nc in nonconformities
        ], ensure_ascii=False, indent=2)

        # Formater prompt Phase 3
        action_plan_prompt_filled = self.action_plan_prompt.format(
            language="FR",  # TODO: dÃ©tecter langue
            campaign_json=campaign_json,
            allowed_roles_json=allowed_roles_json,
            non_conformities_json=non_conformities_json
        )

        # Appel IA pour gÃ©nÃ©ration plan complet
        try:
            logger.info(f"ğŸ“¡ Appel IA pour gÃ©nÃ©rer plan d'action ({len(nonconformities)} NC)...")

            # Informer l'utilisateur
            if progress_callback:
                await self._update_progress(
                    action_plan, db,
                    phase3_status=PhaseStatus.IN_PROGRESS,
                    progress_callback=progress_callback
                )

            response = await self.client.post(
                f"{self.ollama_base_url}/api/generate",
                json={
                    "model": "deepseek-v3.1:671b-cloud",
                    "system": self.system_prompt,
                    "prompt": action_plan_prompt_filled,
                    "stream": False,
                    "format": "json"
                },
                timeout=180.0  # 3 minutes pour gÃ©nÃ©ration complÃ¨te
            )

            if response.status_code == 200:
                result = response.json()

                # Informer l'utilisateur
                if progress_callback:
                    await self._update_progress(
                        action_plan, db,
                        progress_callback=progress_callback
                    )

                ai_plan = json.loads(result['response'])

                # Mettre Ã  jour summary du plan
                summary = ai_plan.get('action_plan_summary', {})
                action_plan.title = summary.get('title', f"Plan d'action - {campaign_info.title if campaign_info else 'Audit'}")
                action_plan.overall_risk_level = summary.get('overall_risk_level', 'moyen')
                action_plan.summary_justification = summary.get('global_justification', '')

                # Informer l'utilisateur
                if progress_callback:
                    await self._update_progress(
                        action_plan, db,
                        progress_callback=progress_callback
                    )

                # CrÃ©er ActionPlanItem pour chaque action
                action_items = []
                for idx, ai_action in enumerate(ai_plan.get('actions', []), 1):
                    try:
                        item = ActionPlanItem(
                            action_plan_id=action_plan_id,
                            status=ActionPlanItemStatus.PROPOSED,
                            local_id=ai_action.get('local_id'),
                            title=ai_action['title'],
                            description=ai_action['description'],
                            objective=ai_action.get('objective', ''),
                            deliverables=ai_action.get('deliverables', []),
                            severity=ActionSeverity[ai_action['severity'].upper()],
                            priority=ActionPriority[ai_action['priority'].upper()],
                            recommended_due_days=ai_action['recommended_due_days'],
                            suggested_role=ai_action['suggested_role'],
                            assignment_method=AssignmentMethod.AI_SUGGESTED,
                            source_question_ids=[UUID(qid) for qid in ai_action.get('source_questions', [])],
                            referential_controls=ai_action.get('referential_controls', []),
                            ai_justifications=ai_action.get('justification', {})
                        )

                        db.add(item)
                        action_items.append(item)

                        # Informer l'utilisateur tous les 5 actions
                        if progress_callback and idx % 5 == 0:
                            await self._update_progress(
                                action_plan, db,
                                progress_callback=progress_callback
                            )

                    except Exception as e:
                        logger.error(f"âŒ Erreur crÃ©ation action {ai_action.get('local_id')}: {str(e)}")

                db.commit()

                # Informer l'utilisateur
                if progress_callback:
                    await self._update_progress(
                        action_plan, db,
                        progress_callback=progress_callback
                    )

                logger.info(f"âœ… Plan d'action gÃ©nÃ©rÃ© : {len(action_items)} actions (regroupÃ©es depuis {len(nonconformities)} NC)")
                return action_items

            else:
                logger.warning(f"âš ï¸ Erreur IA gÃ©nÃ©ration: {response.status_code}, fallback")

                # Informer l'utilisateur
                if progress_callback:
                    await self._update_progress(
                        action_plan, db,
                        progress_callback=progress_callback
                    )

                return await self._fallback_generate_actions(nonconformities, action_plan_id, db)

        except Exception as e:
            logger.error(f"âŒ Erreur appel IA Phase 3: {str(e)}")

            # Informer l'utilisateur
            if progress_callback:
                await self._update_progress(
                    action_plan, db,
                    progress_callback=progress_callback
                )

            return await self._fallback_generate_actions(nonconformities, action_plan_id, db)

    async def _fallback_generate_actions(
        self,
        nonconformities: List[Dict[str, Any]],
        action_plan_id: UUID,
        db: Session
    ) -> List[ActionPlanItem]:
        """
        Fallback : gÃ©nÃ©ration 1 action par NC si IA indisponible.

        Returns:
            Actions gÃ©nÃ©rÃ©es par rÃ¨gles
        """
        logger.info("ğŸ”§ Fallback : gÃ©nÃ©ration actions par rÃ¨gles...")

        action_items = []
        for idx, nc in enumerate(nonconformities):
            ai_result = self._fallback_action_generation(nc)

            item = ActionPlanItem(
                action_plan_id=action_plan_id,
                status=ActionPlanItemStatus.PROPOSED,
                local_id=f"ACT-{idx+1}",
                title=ai_result['title'],
                description=ai_result['description'],
                severity=ActionSeverity[ai_result['severity'].upper()],
                priority=ActionPriority[ai_result['priority'].upper()],
                recommended_due_days=ai_result['recommended_due_days'],
                suggested_role=ai_result['suggested_role'],
                assignment_method=AssignmentMethod.AI_SUGGESTED,
                source_question_ids=[nc['question_id']],
                referential_controls=[nc.get('requirement_code', 'N/A')],
                ai_justifications=ai_result.get('justifications', {})
            )

            db.add(item)
            action_items.append(item)

        db.commit()
        logger.info(f"âœ… Fallback : {len(action_items)} actions gÃ©nÃ©rÃ©es")
        return action_items

    async def _call_ai_for_action(self, nc: Dict[str, Any]) -> Dict[str, Any]:
        """
        Appelle Ollama pour gÃ©nÃ©rer une action corrective.

        Args:
            nc: Non-conformitÃ© avec contexte

        Returns:
            Dict avec title, description, severity, priority, etc.
        """
        # Prompt structurÃ© pour l'IA
        prompt = self._build_action_prompt(nc)

        try:
            # Appel Ollama avec DeepSeek
            response = await self.client.post(
                f"{self.ollama_base_url}/api/generate",
                json={
                    "model": "deepseek-v3.1:671b-cloud",  # ModÃ¨le disponible
                    "prompt": prompt,
                    "stream": False,
                    "format": "json"
                },
                timeout=60.0  # Timeout de 60 secondes pour l'IA
            )

            if response.status_code == 200:
                result = response.json()
                ai_response = json.loads(result['response'])
                return ai_response
            else:
                logger.warning(f"âš ï¸ Erreur Ollama: {response.status_code}, fallback sur rÃ¨gles")
                return self._fallback_action_generation(nc)

        except Exception as e:
            logger.warning(f"âš ï¸ Erreur appel IA: {str(e)}, fallback sur rÃ¨gles")
            return self._fallback_action_generation(nc)

    def _build_action_prompt(self, nc: Dict[str, Any]) -> str:
        """
        Construit le prompt pour l'IA.

        Args:
            nc: Non-conformitÃ©

        Returns:
            Prompt formatÃ©
        """
        return f"""Tu es un expert en cybersÃ©curitÃ© et conformitÃ© rÃ©glementaire.

CONTEXTE:
- Exigence: {nc.get('requirement_code', 'N/A')} - {nc.get('requirement_title', 'N/A')}
- Question: {nc.get('question_text', 'N/A')}
- RÃ©ponse: {nc.get('answer_value', 'N/A')}
- ConformitÃ©: {nc.get('conformite', 'N/A')}
- Risque: {nc.get('risque', 'N/A')}
- Justification: {nc.get('justification', 'N/A')}

TÃ‚CHE:
GÃ©nÃ¨re UNE action corrective structurÃ©e pour combler cette non-conformitÃ©.

RÃˆGLES STRICTES:
1. Severity:
   - critical: ContrÃ´le vital absent (risque majeur immÃ©diat)
   - major: ContrÃ´le important manquant (non-conformitÃ© grave)
   - minor: Ã‰cart limitÃ© (amÃ©lioration nÃ©cessaire)
   - info: Recommandation (amÃ©lioration continue)

2. Priority:
   - P1: Critical + Urgent (30-60 jours)
   - P2: Important + Non urgent (60-120 jours)
   - P3: AmÃ©lioration continue (90-180 jours)

3. Action:
   - ConcrÃ¨te, rÃ©alisable, mesurable
   - Adresse la cause racine
   - S'aligne avec l'exigence

RÃ‰PONSE (JSON strict):
{{
  "title": "Titre court et clair de l'action",
  "description": "Description dÃ©taillÃ©e de l'action Ã  rÃ©aliser avec Ã©tapes concrÃ¨tes",
  "severity": "critical|major|minor|info",
  "priority": "P1|P2|P3",
  "recommended_due_days": 30-180,
  "suggested_role": "RSSI|DPO|CISO|IT Manager|Security Officer",
  "justifications": {{
    "why_action": "Pourquoi cette action est nÃ©cessaire",
    "why_severity": "Pourquoi ce niveau de criticitÃ©",
    "why_priority": "Pourquoi cette prioritÃ©",
    "why_role": "Pourquoi ce rÃ´le est appropriÃ©"
  }}
}}
"""

    def _fallback_action_generation(self, nc: Dict[str, Any]) -> Dict[str, Any]:
        """
        GÃ©nÃ©ration d'action par rÃ¨gles (fallback si IA indisponible).

        Args:
            nc: Non-conformitÃ©

        Returns:
            Action gÃ©nÃ©rÃ©e par rÃ¨gles
        """
        # DÃ©terminer severity basÃ© sur conformitÃ© et risque
        conformite = nc.get('conformite', '')
        risque = nc.get('risque', '')

        if risque == 'critique' or conformite == 'non_conforme':
            severity = 'critical'
            priority = 'P1'
            due_days = 30
        elif risque == 'Ã©levÃ©' or conformite == 'partiel':
            severity = 'major'
            priority = 'P2'
            due_days = 90
        else:
            severity = 'minor'
            priority = 'P3'
            due_days = 120

        return {
            "title": f"Mise en conformitÃ© : {nc.get('requirement_code', 'N/A')}",
            "description": f"Traiter la non-conformitÃ© identifiÃ©e pour l'exigence {nc.get('requirement_code', 'N/A')}. "
                          f"Ã‰tat actuel : {conformite}. Risque : {risque}. "
                          f"Justification : {nc.get('justification', 'N/A')}",
            "severity": severity,
            "priority": priority,
            "recommended_due_days": due_days,
            "suggested_role": "RSSI",
            "justifications": {
                "why_action": "Non-conformitÃ© dÃ©tectÃ©e",
                "why_severity": f"BasÃ© sur conformitÃ©={conformite} et risque={risque}",
                "why_priority": f"PrioritÃ© {priority} selon niveau de risque",
                "why_role": "RSSI par dÃ©faut"
            }
        }

    # ==================== PHASE 4: ASSIGNATION AUTOMATIQUE ====================

    async def phase4_auto_assign(
        self,
        action_items: List[ActionPlanItem],
        campaign_id: UUID,
        db: Session,
        action_plan: ActionPlan,
        progress_callback: Optional[callable] = None
    ) -> List[ActionPlanItem]:
        """
        Phase 4 : Assigne automatiquement les actions aux responsables.

        Logique d'assignation:
        1. Chercher dans role_assignments (mapping explicite)
        2. Fallback sur manager/owner de la campagne
        3. Si audit EXTERNAL: utiliser audit_resp
        4. Fallback final: owner du tenant

        Returns:
            Actions avec assigned_user_id rempli
        """
        logger.info("ğŸ‘¥ Phase 4 : Assignation automatique...")

        # RÃ©cupÃ©rer infos campagne
        campaign_query = text("""
            SELECT c.id, c.manager_id, c.owner_id, c.tenant_id, c.audit_type
            FROM campaign c
            WHERE c.id = CAST(:campaign_id AS uuid)
        """)
        campaign_result = db.execute(campaign_query, {"campaign_id": str(campaign_id)}).fetchone()

        if not campaign_result:
            raise ValueError(f"Campagne {campaign_id} introuvable")

        assigned_count = 0

        for item in action_items:
            try:
                # Tenter assignation
                assigned_user_id = await self._find_assignee(
                    item, campaign_result, db
                )

                if assigned_user_id:
                    item.assigned_user_id = assigned_user_id
                    item.assignment_method = AssignmentMethod.ROLE_BASED
                    assigned_count += 1
                else:
                    # Pas d'assignation trouvÃ©e
                    item.assignment_method = AssignmentMethod.AI_SUGGESTED

                if progress_callback:
                    await self._update_progress(
                        action_plan, db,
                        actions_assigned=assigned_count,
                        progress_callback=progress_callback
                    )

            except Exception as e:
                logger.error(f"âŒ Erreur assignation action {item.id}: {str(e)}")

        db.commit()

        logger.info(f"âœ… {assigned_count}/{len(action_items)} actions assignÃ©es")
        return action_items

    async def _find_assignee(
        self,
        item: ActionPlanItem,
        campaign: Any,
        db: Session
    ) -> Optional[UUID]:
        """
        Trouve le responsable appropriÃ© pour une action.

        Args:
            item: ActionPlanItem Ã  assigner
            campaign: Row de la campagne
            db: Session DB

        Returns:
            UUID du user assignÃ©, ou None
        """
        # 1. Chercher dans role_assignments (TODO: implÃ©menter table)
        # role_query = text(...)

        # 2. Fallback sur manager de la campagne
        if campaign.manager_id:
            return campaign.manager_id

        # 3. Fallback sur owner
        if campaign.owner_id:
            return campaign.owner_id

        # 4. Aucun assignÃ© trouvÃ©
        return None

    # ==================== HELPERS ====================

    async def _update_progress(
        self,
        action_plan: ActionPlan,
        db: Session,
        current_phase: Optional[int] = None,
        phase1_status: Optional[PhaseStatus] = None,
        phase2_status: Optional[PhaseStatus] = None,
        phase3_status: Optional[PhaseStatus] = None,
        phase4_status: Optional[PhaseStatus] = None,
        questions_analyzed: Optional[int] = None,
        total_questions: Optional[int] = None,
        non_conformities_found: Optional[int] = None,
        actions_generated: Optional[int] = None,
        actions_assigned: Optional[int] = None,
        progress_callback: Optional[callable] = None
    ):
        """
        Met Ã  jour la progression dans action_plan.generation_progress.

        Args:
            action_plan: ActionPlan Ã  mettre Ã  jour
            db: Session DB
            current_phase: Phase actuelle (1-4)
            phase1_status...phase4_status: Statuts des phases
            questions_analyzed...actions_assigned: Compteurs
            progress_callback: Fonction pour envoyer SSE
        """
        # RÃ©cupÃ©rer progression actuelle
        progress = action_plan.generation_progress or {}

        # Mettre Ã  jour les champs fournis
        if current_phase is not None:
            progress['current_phase'] = current_phase
        if phase1_status is not None:
            progress['phase1_status'] = phase1_status.value
        if phase2_status is not None:
            progress['phase2_status'] = phase2_status.value
        if phase3_status is not None:
            progress['phase3_status'] = phase3_status.value
        if phase4_status is not None:
            progress['phase4_status'] = phase4_status.value
        if questions_analyzed is not None:
            progress['questions_analyzed'] = questions_analyzed
        if total_questions is not None:
            progress['total_questions'] = total_questions
        if non_conformities_found is not None:
            progress['non_conformities_found'] = non_conformities_found
        if actions_generated is not None:
            progress['actions_generated'] = actions_generated
        if actions_assigned is not None:
            progress['actions_assigned'] = actions_assigned

        # Calculer temps restant estimÃ© (simpliste)
        progress['estimated_time_remaining'] = self._estimate_remaining_time(progress)

        action_plan.generation_progress = progress
        action_plan.updated_at = datetime.now(timezone.utc)

        db.commit()

        # Callback SSE si fourni
        if progress_callback:
            await progress_callback(GenerationProgress(**progress))

    def _estimate_remaining_time(self, progress: Dict) -> int:
        """
        Estime le temps restant en secondes (trÃ¨s simpliste).

        Returns:
            Temps estimÃ© en secondes
        """
        current_phase = progress.get('current_phase', 1)

        # Temps estimÃ© par phase (en secondes)
        phase_times = {1: 10, 2: 5, 3: 60, 4: 10}

        remaining = 0
        for phase in range(current_phase + 1, 5):
            remaining += phase_times.get(phase, 10)

        return remaining

    def _calculate_statistics(self, items: List[ActionPlanItem]) -> Dict[str, Any]:
        """
        Calcule les statistiques du plan d'action.

        Args:
            items: Liste des ActionPlanItem

        Returns:
            Dict avec total, counts par severity, overall_risk
        """
        stats = {
            'total': len(items),
            'critical': 0,
            'major': 0,
            'minor': 0,
            'info': 0,
            'overall_risk': 'low'
        }

        for item in items:
            if item.severity == ActionSeverity.CRITICAL:
                stats['critical'] += 1
            elif item.severity == ActionSeverity.MAJOR:
                stats['major'] += 1
            elif item.severity == ActionSeverity.MINOR:
                stats['minor'] += 1
            elif item.severity == ActionSeverity.INFO:
                stats['info'] += 1

        # DÃ©terminer risque global
        if stats['critical'] > 0:
            stats['overall_risk'] = 'critical'
        elif stats['major'] > 3:
            stats['overall_risk'] = 'high'
        elif stats['major'] > 0:
            stats['overall_risk'] = 'medium'
        else:
            stats['overall_risk'] = 'low'

        return stats
