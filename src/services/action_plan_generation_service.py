"""
Service de g√©n√©ration de plans d'action IA (EN M√âMOIRE UNIQUEMENT).

Pattern identique √† la g√©n√©ration de questions:
- Service g√©n√®re les donn√©es en m√©moire
- Retourne JSON au frontend via SSE
- Frontend affiche l'interface de validation
- Utilisateur valide/modifie
- Frontend appelle /publish pour sauvegarder en DB

Version: 2.0 - Refactorisation compl√®te
Date: 2025-01-23
"""

import logging
from typing import List, Dict, Any, Optional
from uuid import UUID
from datetime import datetime, timezone
from sqlalchemy.orm import Session
from sqlalchemy import text
import json
import httpx
from pathlib import Path
from src.services.clients.deepseek_http_client import DeepSeekHttpClient

logger = logging.getLogger(__name__)


class ActionPlanGenerationService:
    """
    Service de g√©n√©ration de plans d'action EN M√âMOIRE.

    Workflow (5 phases):
    1. Pr√©paration donn√©es (extraction depuis DB)
    2. Analyse IA des r√©ponses (conformit√©/risque)
    3. G√©n√©ration IA du plan (actions structur√©es)
    4. Post-traitement & assignation (mapping utilisateurs)
    5. [FRONTEND] Validation & publication (MANUEL)

    Pattern: G√©n√®re TOUT en m√©moire, retourne Dict JSON.
    """

    def __init__(self, ollama_base_url: str = "http://localhost:11434", model: str = "deepseek-v3.1:671b-cloud"):
        """
        Initialise le service.

        Args:
            ollama_base_url: URL de base d'Ollama pour les appels IA
            model: Nom du mod√®le DeepSeek √† utiliser
        """
        self.ollama_base_url = ollama_base_url
        self.model = model
        self.client = httpx.AsyncClient(timeout=120.0)

        # Charger les prompts depuis les fichiers
        self.prompts_dir = Path(__file__).parent.parent / "prompts" / "action_plan"
        self.system_prompt = self._load_prompt("00_system_prompt.txt")
        self.analysis_prompt = self._load_prompt("02_analysis_prompt.txt")
        self.action_plan_prompt = self._load_prompt("03_action_plan_prompt.txt")

        # Initialiser le client DeepSeek HTTP avec Ollama
        # IMPORTANT: max_tokens augment√© √† 16384 pour √©viter les JSON tronqu√©s
        self.deepseek = DeepSeekHttpClient(
            base_url=ollama_base_url,
            model=model,
            temperature=0.6,
            max_tokens=16384,  # Doubl√© pour √©viter la troncature des r√©ponses JSON longues
            max_retries=3,
            system_prompt=self.system_prompt
        )

        # RGPD: Mapping entity_id -> {label anonyme, vrai nom}
        # Permet d'anonymiser avant envoi IA et remettre vrais noms au retour
        self.entity_mapping = {}

    def _load_prompt(self, filename: str) -> str:
        """Charge un prompt depuis un fichier."""
        prompt_path = self.prompts_dir / filename
        try:
            with open(prompt_path, 'r', encoding='utf-8') as f:
                content = f.read()
                logger.info(f"‚úÖ Prompt charg√©: {filename}")
                return content
        except FileNotFoundError:
            logger.error(f"‚ùå Fichier prompt introuvable: {prompt_path}")
            raise
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement prompt {filename}: {e}")
            raise

    async def _safe_json_parse(self, response_text: str, phase_name: str) -> Dict[str, Any]:
        """
        Parse le JSON de mani√®re robuste avec tentative de r√©paration.

        Args:
            response_text: Texte brut de la r√©ponse IA
            phase_name: Nom de la phase (pour logging)

        Returns:
            Dict pars√©

        Raises:
            Exception si impossible de parser m√™me apr√®s r√©paration
        """
        # D√©tecter si la r√©ponse semble tronqu√©e (indicateurs communs)
        is_likely_truncated = (
            response_text.rstrip().endswith((',', '"', ':', '[', '{')) or
            response_text.count('{') > response_text.count('}') or
            response_text.count('[') > response_text.count(']')
        )

        if is_likely_truncated:
            logger.warning(f"‚ö†Ô∏è JSON potentiellement tronqu√© d√©tect√© en Phase {phase_name}")
            logger.warning(f"   - Derniers 100 caract√®res: ...{response_text[-100:]}")
            logger.warning(f"   - {{ count: {response_text.count('{')}, }} count: {response_text.count('}')}")

        try:
            # Tentative 1: Parse direct
            return json.loads(response_text)
        except json.JSONDecodeError as e:
            logger.warning(f"‚ö†Ô∏è JSON invalide en Phase {phase_name}, tentative de r√©paration...")
            logger.debug(f"R√©ponse brute: {response_text[:1000]}")

        # Tentative 2: Nettoyage basique et retry
        try:
            cleaned = response_text.strip()
            # Enlever les blocs markdown si pr√©sents (```json ... ``` ou ```json ... sans fermeture)
            if cleaned.startswith("```"):
                # Supprimer le premier ```json ou ```
                if cleaned.startswith("```json"):
                    cleaned = cleaned[7:]  # len("```json") = 7
                else:
                    cleaned = cleaned[3:]  # len("```") = 3
                # Supprimer le ``` de fin s'il existe
                if "```" in cleaned:
                    cleaned = cleaned.split("```")[0]
            cleaned = cleaned.strip()

            logger.debug(f"üßπ JSON nettoy√© (premiers 200 chars): {cleaned[:200]}")
            return json.loads(cleaned)
        except json.JSONDecodeError:
            pass

        # Tentative 3: Utiliser json-repair library
        try:
            from json_repair import repair_json
            logger.info("üîß Utilisation de json-repair...")

            # Nettoyer les backticks markdown avant repair
            text_to_repair = response_text.strip()
            if text_to_repair.startswith("```"):
                if text_to_repair.startswith("```json"):
                    text_to_repair = text_to_repair[7:]
                else:
                    text_to_repair = text_to_repair[3:]
                if "```" in text_to_repair:
                    text_to_repair = text_to_repair.split("```")[0]
                text_to_repair = text_to_repair.strip()

            repaired = repair_json(text_to_repair)
            result = json.loads(repaired)
            logger.info(f"‚úÖ JSON r√©par√© avec succ√®s pour Phase {phase_name}")

            # V√©rifier la qualit√© des donn√©es r√©par√©es
            if phase_name == "2-Consolidation":
                nc_list = result.get("consolidated_nonconformities", [])
                incomplete_count = sum(1 for nc in nc_list if not nc.get("consolidated_description") or not nc.get("root_cause"))
                if incomplete_count > 0:
                    logger.warning(f"‚ö†Ô∏è JSON r√©par√© mais {incomplete_count}/{len(nc_list)} NCs ont des champs vides (troncature probable)")
            elif phase_name == "3-Actions":
                actions = result.get("actions", [])
                incomplete_count = sum(1 for a in actions if not a.get("description") or len(a.get("description", "")) < 50)
                if incomplete_count > 0:
                    logger.warning(f"‚ö†Ô∏è JSON r√©par√© mais {incomplete_count}/{len(actions)} actions ont des descriptions incompl√®tes (troncature probable)")

            return result
        except Exception as repair_error:
            logger.error(f"‚ùå √âchec r√©paration JSON: {repair_error}")
            logger.error(f"R√©ponse compl√®te: {response_text[:2000]}")
            raise Exception(
                f"IA a retourn√© du texte non-JSON en Phase {phase_name}. "
                f"Preview: {response_text[:500]}"
            )

    async def generate_action_plan(
        self,
        campaign_id: UUID,
        db: Session,
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """
        G√©n√®re un plan d'action complet EN M√âMOIRE (4 phases IA).

        IMPORTANT: Aucune √©criture en base de donn√©es.
        Retourne un dictionnaire JSON pr√™t pour affichage frontend.

        Args:
            campaign_id: ID de la campagne
            db: Session database (lecture seule)
            progress_callback: Fonction callback pour envoyer progression SSE

        Returns:
            Dict contenant:
            {
                "action_plan_summary": {
                    "title": str,
                    "overall_risk_level": "faible|moyen|√©lev√©|critique",
                    "total_actions": int,
                    "global_justification": str
                },
                "actions": [
                    {
                        "local_id": "ACT-1",
                        "title": str,
                        "description": str,
                        "objective": str,
                        "deliverables": [str],
                        "severity": "critical|major|minor|info",
                        "priority": "P1|P2|P3",
                        "recommended_due_days": int,
                        "suggested_role": str,
                        "source_questions": [str],
                        "referential_controls": [str],
                        "justification": {
                            "why_action": str,
                            "why_severity": str,
                            "why_priority": str,
                            "why_role": str,
                            "why_due_days": str
                        }
                    }
                ],
                "statistics": {
                    "total": int,
                    "critical_count": int,
                    "major_count": int,
                    "minor_count": int,
                    "info_count": int,
                    "overall_risk_level": str
                },
                "metadata": {
                    "campaign_id": str,
                    "generated_at": str,
                    "dominant_language": str
                }
            }
        """
        logger.info(f"üöÄ D√©marrage g√©n√©ration plan d'action pour campagne {campaign_id}")

        try:
            # PHASE 1: Pr√©paration des donn√©es
            if progress_callback:
                await progress_callback("phase1_started", {"message": "Extraction des r√©ponses..."})

            analyzed_responses = await self.phase1_prepare_data(campaign_id, db, progress_callback)

            if progress_callback:
                await progress_callback("phase1_completed", {
                    "questions_analyzed": len(analyzed_responses),
                    "message": f"‚úÖ {len(analyzed_responses)} r√©ponses extraites"
                })

            logger.info(f"‚úÖ Phase 1 : {len(analyzed_responses)} r√©ponses analys√©es")

            # PHASE 2: Analyse IA (conformit√©/risque)
            if progress_callback:
                await progress_callback("phase2_started", {"message": "Analyse IA des conformit√©s..."})

            nonconformities = await self.phase2_analyze_conformity(
                analyzed_responses, campaign_id, db, progress_callback
            )

            if progress_callback:
                await progress_callback("phase2_completed", {
                    "non_conformities_found": len(nonconformities),
                    "message": f"‚úÖ {len(nonconformities)} non-conformit√©s d√©tect√©es"
                })

            logger.info(f"‚úÖ Phase 2 : {len(nonconformities)} NC d√©tect√©es")

            # PHASE 3: G√©n√©ration IA du plan
            if progress_callback:
                await progress_callback("phase3_started", {"message": "G√©n√©ration des actions..."})

            action_plan_data = await self.phase3_generate_actions(
                nonconformities, campaign_id, db, progress_callback
            )

            if progress_callback:
                await progress_callback("phase3_completed", {
                    "actions_generated": len(action_plan_data.get("actions", [])),
                    "message": f"‚úÖ {len(action_plan_data.get('actions', []))} actions g√©n√©r√©es"
                })

            logger.info(f"‚úÖ Phase 3 : {len(action_plan_data.get('actions', []))} actions g√©n√©r√©es")

            # PHASE 4: Post-traitement & assignation
            if progress_callback:
                await progress_callback("phase4_started", {"message": "Assignation automatique..."})

            final_plan = await self.phase4_assign_users(
                action_plan_data, campaign_id, db, progress_callback
            )

            if progress_callback:
                await progress_callback("phase4_completed", {
                    "actions_assigned": len(final_plan.get("actions", [])),
                    "message": "‚úÖ Assignation termin√©e"
                })

            logger.info(f"‚úÖ Phase 4 : {len(final_plan.get('actions', []))} actions assign√©es")

            # PHASE 5: Pr√©paration de la validation (PAS de sauvegarde DB)
            if progress_callback:
                await progress_callback("phase5_started", {"message": "Pr√©paration de la validation..."})

            # RGPD: Remettre les vrais noms d'entit√©s (d√©-anonymisation)
            logger.info("üîì RGPD: Remapping des noms r√©els d'entit√©s...")
            for action in final_plan.get("actions", []):
                entity_id = action.get("entity_id")
                if entity_id and entity_id in self.entity_mapping:
                    action["entity_name"] = self.entity_mapping[entity_id]["real_name"]
                    logger.debug(f"üîì Action {action.get('local_id')}: {self.entity_mapping[entity_id]['label']} ‚Üí {action['entity_name']}")

            # Ajouter m√©tadonn√©es finales (sans ID car pas encore sauvegard√©)
            final_plan["metadata"] = {
                "campaign_id": str(campaign_id),
                "generated_at": datetime.now(timezone.utc).isoformat(),
                "dominant_language": "fr",  # TODO: d√©tecter depuis les r√©ponses
                "status": "READY_FOR_VALIDATION"  # Pas encore en DB
            }

            if progress_callback:
                await progress_callback("phase5_completed", {
                    "message": "‚úÖ Pr√™t pour validation"
                })

            logger.info(f"üéâ Plan d'action g√©n√©r√© avec succ√®s : {len(final_plan.get('actions', []))} actions")
            return final_plan

        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la g√©n√©ration : {str(e)}", exc_info=True)
            if progress_callback:
                await progress_callback("error", {"message": str(e)})
            raise

    # ==================== PHASE 1: PR√âPARATION DES DONN√âES ====================

    async def phase1_prepare_data(
        self,
        campaign_id: UUID,
        db: Session,
        progress_callback: Optional[callable] = None
    ) -> List[Dict[str, Any]]:
        """
        Phase 1 : Collecte de toutes les r√©ponses du questionnaire.

        Returns:
            Liste des r√©ponses avec m√©tadonn√©es (question, contr√¥le, domaine, etc.)
        """
        logger.info("üìã Phase 1 : Pr√©paration des donn√©es...")

        # Requ√™te pour r√©cup√©rer toutes les r√©ponses avec contexte
        # IMPORTANT: Inclut entity_id et entity_name pour permettre √† l'IA de g√©n√©rer
        # des actions sp√©cifiques par entit√© (√©vite la sur-consolidation)
        # FIX: Utilise a.entity_id directement au lieu de la jointure via organization
        query = text("""
            SELECT
                qr.id as response_id,
                qr.question_id,
                qr.answer_value,
                qr.comment,
                q.question_text,
                q.response_type,
                req.id as requirement_id,
                req.official_code as requirement_code,
                req.title as requirement_title,
                req.requirement_text,
                d.title as domain_name,
                d.code as domain_code,
                ee.id as entity_id,
                ee.name as entity_name,
                a.id as audit_id,
                COUNT(DISTINCT aa.id) as attachments_count,
                STRING_AGG(DISTINCT aa.original_filename, ', ') as attachment_filenames,
                STRING_AGG(DISTINCT aa.attachment_type, ', ') as attachment_types
            FROM question_answer qr
            JOIN question q ON qr.question_id = q.id
            JOIN audit a ON qr.audit_id = a.id
            JOIN ecosystem_entity ee ON a.entity_id = ee.id
            JOIN campaign c ON qr.campaign_id = c.id
            JOIN campaign_scope cs ON c.scope_id = cs.id
            LEFT JOIN requirement req ON q.requirement_id = req.id
            LEFT JOIN domain d ON req.domain_id = d.id
            LEFT JOIN answer_attachment aa ON qr.id = aa.answer_id
                AND aa.virus_scan_status = 'clean'
                AND aa.is_active = true
            WHERE qr.campaign_id = CAST(:campaign_id AS uuid)
              AND qr.is_current = true
              AND ee.id = ANY(cs.entity_ids)
            GROUP BY qr.id, qr.question_id, qr.answer_value, qr.comment,
                     q.question_text, q.response_type, req.id,
                     req.official_code, req.title, req.requirement_text,
                     d.title, d.code, ee.id, ee.name, a.id
            ORDER BY ee.name, d.title, req.official_code
        """)

        result = db.execute(query, {"campaign_id": str(campaign_id)})
        rows = result.fetchall()

        # RGPD: Cr√©er un mapping entity_id -> label anonyme (Entit√© 1, Entit√© 2, ...)
        # R√©initialiser le mapping pour cette g√©n√©ration
        self.entity_mapping = {}
        entity_counter = 1

        analyzed = []
        total = len(rows)

        for idx, row in enumerate(rows):
            # Cr√©er label anonyme si premi√®re fois qu'on voit cette entit√©
            entity_id_str = str(row.entity_id)
            if entity_id_str not in self.entity_mapping:
                self.entity_mapping[entity_id_str] = {
                    "label": f"Entit√© {entity_counter}",
                    "real_name": row.entity_name
                }
                entity_counter += 1
                logger.info(f"üîí RGPD: Anonymisation {row.entity_name} ‚Üí {self.entity_mapping[entity_id_str]['label']}")

            analyzed.append({
                "response_id": str(row.response_id),
                "question_id": str(row.question_id),
                "question_text": row.question_text,
                "response_type": row.response_type,
                "answer_value": row.answer_value,
                "comment": row.comment or "",
                "requirement_id": str(row.requirement_id) if row.requirement_id else None,
                "requirement_code": row.requirement_code,
                "requirement_title": row.requirement_title,
                "requirement_text": row.requirement_text,
                "domain_name": row.domain_name,
                "domain_code": row.domain_code,
                "entity_id": entity_id_str,
                "entity_name": self.entity_mapping[entity_id_str]["label"],  # Label anonyme pour l'IA
                "audit_id": str(row.audit_id),
                "attachments_count": row.attachments_count or 0,  # Nombre de preuves fournies
                "attachment_filenames": row.attachment_filenames or "",  # Noms des fichiers (evidence)
                "attachment_types": row.attachment_types or "",  # Types des pi√®ces jointes
            })

            # Envoyer progression tous les 10 items
            if progress_callback and (idx + 1) % 10 == 0:
                await progress_callback("phase1_progress", {
                    "questions_analyzed": idx + 1,
                    "total_questions": total
                })

        # Log des entit√©s trouv√©es pour debug
        unique_entities = set((r["entity_id"], r["entity_name"]) for r in analyzed)
        logger.info(f"üìä Phase 1: {len(analyzed)} r√©ponses de {len(unique_entities)} entit√©s distinctes")
        for entity_id, entity_label in unique_entities:
            entity_responses = [r for r in analyzed if r["entity_id"] == entity_id]
            real_name = self.entity_mapping.get(entity_id, {}).get("real_name", "?")
            logger.info(f"   - {entity_label} ({real_name}): {len(entity_responses)} r√©ponses")

        return analyzed

    # ==================== PHASE 2: ANALYSE IA ====================

    async def phase2_analyze_conformity(
        self,
        analyzed_responses: List[Dict[str, Any]],
        campaign_id: UUID,
        db: Session,
        progress_callback: Optional[callable] = None
    ) -> List[Dict[str, Any]]:
        """
        Phase 2 : Analyse IA de TOUTES les r√©ponses avec CONSOLIDATION.

        Deux √©tapes:
        1. D√©tection simple des NC via parsing JSON
        2. Appel IA pour CONSOLIDATION (grouper NCs similaires, calculer risques)

        Returns:
            Liste consolid√©e de non-conformit√©s avec scores de risque
        """
        logger.info(f"ü§ñ Phase 2 : Analyse IA de {len(analyzed_responses)} questions...")

        # √âTAPE 1: D√©tection simple des NCs (parsing JSON)
        raw_nonconformities = []

        for response in analyzed_responses:
            answer_value = response.get("answer_value", {})

            # Si answer_value est une string JSON, la parser
            if isinstance(answer_value, str):
                try:
                    answer_value = json.loads(answer_value)
                except:
                    answer_value = {}

            # D√©terminer la conformit√© selon le type de r√©ponse
            is_non_conforme = False
            is_partiel = False
            value_str = ""

            if isinstance(answer_value, dict):
                # R√©ponse bool√©enne
                if "bool" in answer_value:
                    bool_val = answer_value["bool"]
                    if bool_val is False:
                        is_non_conforme = True
                        value_str = "Non"
                    else:
                        value_str = "Oui"

                # R√©ponse √† choix multiples
                elif "choice" in answer_value:
                    choice = str(answer_value["choice"]).lower()
                    if choice in ["non", "no", "non conforme", "non-conforme"]:
                        is_non_conforme = True
                        value_str = answer_value["choice"]
                    elif choice in ["partiellement", "partiel", "partial", "en cours"]:
                        is_partiel = True
                        value_str = answer_value["choice"]
                    else:
                        value_str = answer_value["choice"]

                # R√©ponse num√©rique (seuil bas = risque)
                elif "number" in answer_value:
                    num_val = answer_value.get("number", 0)
                    value_str = str(num_val)
                    if num_val < 3:
                        is_partiel = True

                # R√©ponse fichiers manquants
                elif "files" in answer_value:
                    files = answer_value.get("files", [])
                    if len(files) == 0:
                        is_partiel = True
                        value_str = "Aucun fichier fourni"

            # Ajouter aux NCs brutes si d√©tect√©
            if is_non_conforme or is_partiel:
                raw_nonconformities.append({
                    **response,
                    "detected_value": value_str,
                    "is_critical": is_non_conforme
                })

        logger.info(f"üîç D√©tection brute : {len(raw_nonconformities)} NC sur {len(analyzed_responses)} r√©ponses")

        # Log r√©partition des NCs par entit√©
        nc_by_entity = {}
        for nc in raw_nonconformities:
            entity_name = nc.get("entity_name", "?")
            entity_id = nc.get("entity_id", "?")
            key = f"{entity_name} ({entity_id})"
            nc_by_entity[key] = nc_by_entity.get(key, 0) + 1
        logger.info(f"üìä R√©partition NCs brutes par entit√©:")
        for entity, count in nc_by_entity.items():
            logger.info(f"   - {entity}: {count} NC")

        # √âTAPE 2: Consolidation IA (si NCs d√©tect√©es)
        if len(raw_nonconformities) == 0:
            logger.info("‚úÖ Aucune NC d√©tect√©e, fin de Phase 2")
            return []

        logger.info("=" * 80)
        logger.info("üöÄ D√âBUT CONSOLIDATION IA (PHASE 2 - PASSE 1)")
        logger.info("=" * 80)

        try:
            # TRAITEMENT PAR BATCHES pour √©viter la troncature JSON
            # Le mod√®le cloud a une limite de g√©n√©ration - on traite par lots de 10 NCs
            BATCH_SIZE = 10
            all_consolidated = []
            total_batches = (len(raw_nonconformities) + BATCH_SIZE - 1) // BATCH_SIZE

            for batch_idx in range(total_batches):
                start_idx = batch_idx * BATCH_SIZE
                end_idx = min(start_idx + BATCH_SIZE, len(raw_nonconformities))
                batch_ncs = raw_nonconformities[start_idx:end_idx]

                logger.info(f"üì¶ Batch {batch_idx + 1}/{total_batches}: NCs {start_idx + 1} √† {end_idx}")

                # Pr√©parer les NCs du batch en JSON
                nc_json_data = []
                for nc in batch_ncs:
                    nc_json_data.append({
                        "question_id": nc.get("question_id"),
                        "question_text": nc.get("question_text", ""),
                        "requirement_code": nc.get("requirement_code", "N/A"),
                        "requirement_title": nc.get("requirement_title", ""),
                        "domain_name": nc.get("domain_name", ""),
                        "entity_id": nc.get("entity_id", ""),
                        "entity_name": nc.get("entity_name", ""),
                        "detected_value": nc.get("detected_value", ""),
                        "comment": nc.get("comment", ""),
                        "attachments_count": nc.get("attachments_count", 0),
                        "attachment_filenames": nc.get("attachment_filenames", ""),
                        "attachment_types": nc.get("attachment_types", "")
                    })

                nc_json_str = json.dumps(nc_json_data, indent=2, ensure_ascii=False)

                logger.info(f"üîç DEBUG Batch {batch_idx + 1}: Envoi de {len(nc_json_data)} NCs")

                user_prompt = self.analysis_prompt.replace("{{total_responses}}", str(len(analyzed_responses)))
                user_prompt = user_prompt.replace("{{nc_count}}", str(len(batch_ncs)))
                user_prompt = user_prompt.replace("{{campaign_id}}", str(campaign_id))
                user_prompt = user_prompt.replace("{{nonconformities_json}}", nc_json_str)

                logger.info(f"üì§ Envoi √† Ollama DeepSeek (Batch {batch_idx + 1}):")
                logger.info(f"   - Mod√®le: {self.deepseek.model}")
                logger.info(f"   - Temp√©rature: {self.deepseek.temperature}")
                logger.info(f"   - Max tokens: {self.deepseek.max_tokens}")
                logger.info(f"   - NCs dans ce batch: {len(batch_ncs)}")
                logger.info(f"ü§ñ Appel Ollama DeepSeek pour consolidation batch {batch_idx + 1}...")

                # Appel Ollama DeepSeek avec retry logic
                response_text = await self.deepseek.call_with_retry(
                    user_prompt=user_prompt,
                    system_prompt=self.system_prompt
                )

                # Parser la r√©ponse JSON avec r√©paration si n√©cessaire
                response = await self._safe_json_parse(response_text, f"2-Consolidation-Batch{batch_idx + 1}")

                batch_consolidated = response.get("consolidated_nonconformities", [])
                logger.info(f"‚úÖ Batch {batch_idx + 1}: {len(batch_ncs)} NC ‚Üí {len(batch_consolidated)} clusters")

                all_consolidated.extend(batch_consolidated)

                # Callback de progression
                if progress_callback:
                    await progress_callback("phase2_batch_progress", {
                        "batch": batch_idx + 1,
                        "total_batches": total_batches,
                        "batch_nc_count": len(batch_ncs),
                        "batch_consolidated_count": len(batch_consolidated)
                    })

            logger.info(f"‚úÖ CONSOLIDATION TERMIN√âE: {len(raw_nonconformities)} NC ‚Üí {len(all_consolidated)} clusters total")
            logger.info("=" * 80)

            # Enrichir chaque NC consolid√©e avec les m√©tadonn√©es originales
            # ET compl√©ter les champs manquants si le JSON √©tait tronqu√©
            for nc in all_consolidated:
                # Retrouver les questions sources
                source_ids = nc.get("source_question_ids", [])
                source_responses = [r for r in raw_nonconformities if r["question_id"] in source_ids]

                # Ajouter m√©tadonn√©es du premier source
                if source_responses:
                    first_source = source_responses[0]
                    nc["requirement_code"] = first_source.get("requirement_code")
                    nc["requirement_title"] = first_source.get("requirement_title")
                    nc["domain_name"] = first_source.get("domain_name")
                    nc["domain_code"] = first_source.get("domain_code")
                    nc["entity_id"] = first_source.get("entity_id")
                    nc["entity_name"] = first_source.get("entity_name")

                    # Si champs IA sont vides (JSON tronqu√©), utiliser les donn√©es brutes comme fallback
                    if not nc.get("consolidated_description"):
                        nc["consolidated_description"] = f"Non-conformit√© d√©tect√©e: {first_source.get('question_text', '')[:200]}"
                        logger.warning(f"‚ö†Ô∏è consolidated_description manquant pour NC, fallback sur question_text")

                    if not nc.get("root_cause"):
                        nc["root_cause"] = f"R√©ponse: {first_source.get('detected_value', 'Non conforme')}. Commentaire: {first_source.get('comment', 'N/A')[:150]}"
                        logger.warning(f"‚ö†Ô∏è root_cause manquant pour NC, fallback sur comment")

                    if not nc.get("current_situation"):
                        nc["current_situation"] = f"Question: {first_source.get('question_text', '')[:150]}. R√©ponse: {first_source.get('detected_value', 'NC')}"

                    if not nc.get("gap_description"):
                        nc["gap_description"] = f"√âcart constat√© sur l'exigence {nc.get('requirement_code', 'N/A')}"

                    # S'assurer que risk_score existe
                    if not nc.get("risk_score") or nc.get("risk_score") == 0:
                        # Calculer un score basique bas√© sur is_critical
                        nc["risk_score"] = 16 if first_source.get("is_critical") else 9
                        nc["impact"] = 4 if first_source.get("is_critical") else 3
                        nc["probability"] = 4 if first_source.get("is_critical") else 3

            if progress_callback:
                await progress_callback("phase2_progress", {
                    "raw_nc_count": len(raw_nonconformities),
                    "consolidated_count": len(all_consolidated)
                })

            return all_consolidated

        except Exception as e:
            logger.error(f"‚ùå Erreur consolidation IA Phase 2 : {str(e)}", exc_info=True)
            # PAS DE FALLBACK - Remonter l'erreur
            raise Exception(f"√âchec de la consolidation IA des non-conformit√©s: {str(e)}")

    # ==================== PHASE 3: G√âN√âRATION ACTIONS IA ====================

    async def phase3_generate_actions(
        self,
        nonconformities: List[Dict[str, Any]],
        campaign_id: UUID,
        db: Session,
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """
        Phase 3 : G√©n√©ration IA du plan d'action structur√© avec DEEPSEEK.

        L'IA g√©n√®re des actions correctives SMART avec justifications compl√®tes.

        Returns:
            Dict avec action_plan_summary + actions
        """
        logger.info(f"ü§ñ Phase 3 : G√©n√©ration IA du plan d'action ({len(nonconformities)} NC)...")

        # Si aucune NC, retourner plan vide
        if len(nonconformities) == 0:
            logger.info("‚úÖ Aucune action √† g√©n√©rer")
            return {
                "action_plan_summary": {
                    "title": f"Plan d'actions - Campagne {campaign_id}",
                    "overall_risk_level": "faible",
                    "total_actions": 0,
                    "global_justification": "Aucune non-conformit√© d√©tect√©e. Organisation en conformit√© totale."
                },
                "actions": [],
                "statistics": {
                    "total": 0,
                    "critical_count": 0,
                    "major_count": 0,
                    "minor_count": 0,
                    "info_count": 0,
                    "overall_risk_level": "faible"
                }
            }

        logger.info("=" * 80)
        logger.info("üöÄ D√âBUT G√âN√âRATION ACTIONS (PHASE 3 - PASSE 2)")
        logger.info("=" * 80)

        try:
            # TRAITEMENT PAR BATCHES pour √©viter la troncature JSON
            # Le mod√®le cloud a une limite de g√©n√©ration - on traite par lots de 10 NCs
            BATCH_SIZE = 10
            all_actions = []
            total_batches = (len(nonconformities) + BATCH_SIZE - 1) // BATCH_SIZE
            action_plan_summary = {}

            for batch_idx in range(total_batches):
                start_idx = batch_idx * BATCH_SIZE
                end_idx = min(start_idx + BATCH_SIZE, len(nonconformities))
                batch_ncs = nonconformities[start_idx:end_idx]

                logger.info(f"üì¶ Batch {batch_idx + 1}/{total_batches}: NCs {start_idx + 1} √† {end_idx}")

                # Pr√©parer le contexte des NC consolid√©es pour l'IA
                nc_context = []
                for nc in batch_ncs:
                    nc_context.append({
                        "requirement_code": nc.get("requirement_code", "N/A"),
                        "requirement_title": nc.get("requirement_title", ""),
                        "entity_id": nc.get("entity_id", ""),  # ‚úÖ OBLIGATOIRE - Identifiant entit√©
                        "entity_name": nc.get("entity_name", ""),  # ‚úÖ OBLIGATOIRE - Nom anonymis√© (Entit√© 1, 2, 3)
                        "consolidated_description": nc.get("consolidated_description", ""),
                        "risk_score": nc.get("risk_score", 0),
                        "impact": nc.get("impact", 0),
                        "probability": nc.get("probability", 0),
                        "source_question_ids": nc.get("source_question_ids", []),
                        "domain_name": nc.get("domain_name", ""),
                        "root_cause": nc.get("root_cause", ""),  # ‚úÖ Cause racine identifi√©e en Phase 2
                        "current_situation": nc.get("current_situation", ""),  # ‚úÖ √âtat actuel constat√©
                        "gap_description": nc.get("gap_description", "")  # ‚úÖ Description pr√©cise de l'√©cart
                    })

                nc_json_str = json.dumps(nc_context, indent=2, ensure_ascii=False)

                # üîç DEBUG: Afficher le contexte envoy√© √† l'IA (premi√®res it√©rations seulement)
                if batch_idx == 0:
                    logger.info(f"üîç DEBUG Phase 3: Contexte NC envoy√© √† l'IA:")
                    logger.info(f"üîç DEBUG Phase 3: Nombre de NCs dans ce batch: {len(nc_context)}")
                    for idx, nc in enumerate(nc_context[:3]):  # Afficher les 3 premi√®res
                        logger.info(f"üîç DEBUG Phase 3: NC {idx+1}:")
                        logger.info(f"   - entity_id: {nc.get('entity_id')}")
                        logger.info(f"   - entity_name: {nc.get('entity_name')}")
                        logger.info(f"   - requirement_code: {nc.get('requirement_code')}")
                        logger.info(f"   - requirement_title: {nc.get('requirement_title')}")
                        logger.info(f"   - consolidated_description: {nc.get('consolidated_description')[:100] if nc.get('consolidated_description') else 'VIDE'}...")
                        logger.info(f"   - risk_score: {nc.get('risk_score')}")
                        logger.info(f"   - source_question_ids: {nc.get('source_question_ids')}")

                # Pr√©parer le prompt
                user_prompt = self.action_plan_prompt.replace("{{nc_count}}", str(len(batch_ncs)))
                user_prompt = user_prompt.replace("{{nc_json}}", nc_json_str)

                logger.info(f"üì§ Envoi √† Ollama DeepSeek (Batch {batch_idx + 1}):")
                logger.info(f"   - Mod√®le: {self.deepseek.model}")
                logger.info(f"   - Temp√©rature: {self.deepseek.temperature}")
                logger.info(f"   - Max tokens: {self.deepseek.max_tokens}")
                logger.info(f"   - NCs dans ce batch: {len(batch_ncs)}")
                logger.info(f"ü§ñ Appel Ollama DeepSeek pour g√©n√©ration d'actions correctives batch {batch_idx + 1}...")

                # Appel Ollama DeepSeek avec retry logic
                response_text = await self.deepseek.call_with_retry(
                    user_prompt=user_prompt,
                    system_prompt=self.system_prompt
                )

                # Parser la r√©ponse JSON avec r√©paration si n√©cessaire
                response = await self._safe_json_parse(response_text, f"3-Actions-Batch{batch_idx + 1}")

                # Extraire les donn√©es g√©n√©r√©es
                if batch_idx == 0:
                    # Premier batch: r√©cup√©rer le summary global
                    action_plan_summary = response.get("action_plan_summary", {})

                batch_actions = response.get("actions", [])
                logger.info(f"‚úÖ Batch {batch_idx + 1}: {len(batch_ncs)} NC ‚Üí {len(batch_actions)} actions")

                all_actions.extend(batch_actions)

                # Callback de progression
                if progress_callback:
                    await progress_callback("phase3_batch_progress", {
                        "batch": batch_idx + 1,
                        "total_batches": total_batches,
                        "batch_nc_count": len(batch_ncs),
                        "batch_actions_count": len(batch_actions)
                    })

            # Utiliser all_actions comme actions finales
            actions = all_actions

            logger.info(f"‚úÖ G√âN√âRATION TERMIN√âE: {len(actions)} actions cr√©√©es depuis {len(nonconformities)} NC (en {total_batches} batches)")
            logger.info("=" * 80)

            # Enrichir chaque action avec les source_questions r√©elles
            for idx, action in enumerate(actions):
                # Mapper les clusters_ids aux source_question_ids
                cluster_ids = action.get("source_clusters", [])
                all_source_questions = []

                logger.info(f"üîç Action {idx+1}: source_clusters = {cluster_ids}")
                logger.info(f"üîç Action {idx+1}: Nombre de NCs disponibles = {len(nonconformities)}")

                for cluster_id in cluster_ids:
                    # Retrouver la NC correspondante
                    matching_nc = next((nc for nc in nonconformities if nc.get("requirement_code") == cluster_id), None)
                    if matching_nc:
                        nc_questions = matching_nc.get("source_question_ids", [])
                        all_source_questions.extend(nc_questions)
                        logger.info(f"   ‚úÖ Cluster '{cluster_id}' ‚Üí {len(nc_questions)} questions: {nc_questions}")
                    else:
                        logger.warning(f"   ‚ö†Ô∏è Cluster '{cluster_id}' introuvable dans les NCs")
                        logger.warning(f"   üìã NCs disponibles: {[nc.get('requirement_code') for nc in nonconformities]}")

                action["source_questions"] = all_source_questions
                action["local_id"] = f"ACT-{idx + 1}"

                logger.info(f"‚úÖ Action {idx+1} '{action.get('title', '')[:50]}...': {len(all_source_questions)} source_questions")
                logger.info(f"üìã source_questions final: {all_source_questions}")

                # Fallback si certains champs manquent
                if not action.get("severity"):
                    action["severity"] = "minor"
                if not action.get("priority"):
                    action["priority"] = "P2"
                if not action.get("recommended_due_days"):
                    action["recommended_due_days"] = 60
                if not action.get("suggested_role"):
                    action["suggested_role"] = "RSSI"

            # Calculer statistiques
            stats = self._calculate_statistics(actions)

            # Construire r√©sultat final
            result = {
                "action_plan_summary": {
                    "title": action_plan_summary.get("title", f"Plan d'actions - Campagne {campaign_id}"),
                    "overall_risk_level": action_plan_summary.get("overall_risk_level", stats["overall_risk_level"]),
                    "total_actions": len(actions),
                    "global_justification": action_plan_summary.get("global_justification", f"{len(nonconformities)} non-conformit√©s consolid√©es en {len(actions)} actions correctives.")
                },
                "actions": actions,
                "statistics": stats
            }

            if progress_callback:
                await progress_callback("phase3_progress", {
                    "nc_count": len(nonconformities),
                    "actions_generated": len(actions)
                })

            return result

        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration IA Phase 3 : {str(e)}", exc_info=True)
            # PAS DE FALLBACK - Remonter l'erreur
            raise Exception(f"√âchec de la g√©n√©ration IA du plan d'action: {str(e)}")

    # ==================== PHASE 4: POST-TRAITEMENT & ASSIGNATION ====================

    async def phase4_assign_users(
        self,
        action_plan_data: Dict[str, Any],
        campaign_id: UUID,
        db: Session,
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """
        Phase 4 : Assignation automatique des responsables.

        Logique d'assignation :
        1. Tenter d'assigner √† un utilisateur avec le r√¥le correspondant dans le tenant
        2. Fallback : Assigner √† un auditeur de la campagne
        3. Si aucun mapping trouv√© : laisser non assign√©

        Returns:
            Dict avec actions assign√©es (champ assigned_user_id ajout√©)
        """
        logger.info(f"üë• Phase 4 : Assignation automatique...")

        # R√©cup√©rer le tenant_id de la campagne
        campaign_query = text("""
            SELECT c.tenant_id
            FROM campaign c
            WHERE c.id = CAST(:campaign_id AS uuid)
        """)
        campaign_result = db.execute(campaign_query, {"campaign_id": str(campaign_id)})
        campaign_row = campaign_result.mappings().first()

        if not campaign_row:
            logger.warning(f"‚ö†Ô∏è Campagne {campaign_id} introuvable pour assignation")
            return action_plan_data

        tenant_id = campaign_row.tenant_id

        # Mapping des r√¥les sugg√©r√©s vers les r√¥les syst√®me
        role_mapping = {
            "RSSI": ["RSSI", "RSSI externe"],
            "DSI": ["Administrateur (Tenant)", "Chef de projet"],
            "DPO": ["Directeur de conformit√© / DPO", "DPO externe"],
            "Directeur g√©n√©ral": ["Administrateur (Tenant)"],
            "Responsable RH": ["Administrateur (Tenant)"],
            "Chef de projet": ["Chef de projet"],
            "Auditeur": ["Auditeur"]
        }

        actions = action_plan_data.get("actions", [])
        assigned_count = 0

        for idx, action in enumerate(actions):
            suggested_role = action.get("suggested_role", "")

            assigned_user_id = None

            # √âtape 1 : Chercher un utilisateur avec le r√¥le correspondant
            matched_roles = role_mapping.get(suggested_role, [suggested_role])

            user_query = text("""
                SELECT DISTINCT u.id
                FROM users u
                JOIN user_role ur ON u.id = ur.user_id
                JOIN role r ON ur.role_id = r.id
                WHERE u.tenant_id = CAST(:tenant_id AS uuid)
                  AND r.name = ANY(:role_names)
                  AND u.is_active = true
                LIMIT 1
            """)

            result = db.execute(user_query, {
                "tenant_id": str(tenant_id),
                "role_names": matched_roles
            })
            user_row = result.first()

            if user_row:
                assigned_user_id = str(user_row[0])
                assigned_count += 1
                logger.debug(f"‚úÖ Action {idx+1} assign√©e √† {assigned_user_id} (r√¥le: {suggested_role})")
            else:
                # √âtape 2 : Fallback vers un auditeur de la campagne
                auditor_query = text("""
                    SELECT u.id
                    FROM users u
                    JOIN campaign_user cu ON u.id = cu.user_id
                    WHERE cu.campaign_id = CAST(:campaign_id AS uuid)
                      AND cu.role = 'auditor'
                      AND cu.is_active = true
                    LIMIT 1
                """)

                result = db.execute(auditor_query, {"campaign_id": str(campaign_id)})
                auditor_row = result.first()

                if auditor_row:
                    assigned_user_id = str(auditor_row[0])
                    assigned_count += 1
                    logger.debug(f"‚úÖ Action {idx+1} assign√©e √† auditeur (fallback)")

            # Mettre √† jour l'action avec l'assignation
            action["assigned_user_id"] = assigned_user_id

            # Envoyer progression tous les 3 items
            if progress_callback and (idx + 1) % 3 == 0:
                await progress_callback("phase4_progress", {
                    "actions_assigned": assigned_count,
                    "actions_generated": len(actions)
                })

        logger.info(f"‚úÖ Phase 4 : {assigned_count}/{len(actions)} actions assign√©es")

        return action_plan_data

    # ==================== UTILITAIRES ====================

    def _calculate_statistics(self, actions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Calcule les statistiques sur les actions."""
        severity_counts = {
            "critical": 0,
            "major": 0,
            "minor": 0,
            "info": 0
        }

        for action in actions:
            severity = action.get("severity", "minor")
            if severity in severity_counts:
                severity_counts[severity] += 1

        # D√©terminer niveau de risque global
        if severity_counts["critical"] > 0:
            overall_risk = "critique"
        elif severity_counts["major"] > 2:
            overall_risk = "√©lev√©"
        elif severity_counts["major"] > 0 or severity_counts["minor"] > 5:
            overall_risk = "moyen"
        else:
            overall_risk = "faible"

        return {
            "total": len(actions),
            "critical_count": severity_counts["critical"],
            "major_count": severity_counts["major"],
            "minor_count": severity_counts["minor"],
            "info_count": severity_counts["info"],
            "overall_risk_level": overall_risk
        }
